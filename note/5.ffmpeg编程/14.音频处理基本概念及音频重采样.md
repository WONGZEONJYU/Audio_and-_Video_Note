# 1. 重点问题

如何进⾏重采样?

采样率不⼀样的时候pts怎么处理?

[[官⽅参考⽂档]](http://ffmpeg.org/doxygen/trunk/group__lswr.html)

# 2. 重采样

## 2.1 什么是重采样

所谓的重采样 , 就是改变音频的 **$\color{red}{\mathbf{采样率、sample\ format、声道数等参数}}$** , 使之按照我们期望的参数输出

## 2.2 为什么要重采样

为什么要重采样?当然是原有的音频参数不满⾜我们的需求 , 比如在FFmpeg解码音频的时候 , 不同的音源有不同的格式 , 采样率等 , 在解码后的数据中的这些参数也会不⼀致 ( 最新FFmpeg 解码音频后 , 音频格式为 `AV_SAMPLE_FMT_FLTP` , 这个参数应该是⼀致的 ) , 如果我们接下来需要使⽤解码后的音频数据做其他操作 , 而这些参数的不⼀致导致会有很多额外工作 , 此时直接对其进行重采样 , 获取我们制定的音频参数 , 这样就会方便很多
再比如在将⾳频进⾏SDL播放时候 , 因为当前的SDL2.0不支持planar格式 , 也不支持浮点型的⽽最新的FFMPEG 16年会将音频解码为`AV_SAMPLE_FMT_FLTP` 格式 , 因此此时就需要我们对其重采样 , 使之可以在SDL2.0上进⾏播放

## 2.3 可调节的参数

通过重采样 , 我们可以对 :

1. **$\color{red}{\mathbf{sample\ rate(采样率)}}$**
2. **$\color{red}{\mathbf{sample\ format(采样格式)}}$**
3. **$\color{red}{\mathbf{channel\ layout(通道布局,可以通过此参数获取声道数)}}$**

# 3. 对应参数解析

## 3.1 采样率

采样设备每秒抽取样本的次数

## 3.2采样格式及量化精度(位宽)

每种⾳频格式有不同的量化精度 (位宽) , 位数越多 , 表示值就越精确 , 声音表现自然就越精准。FFMpeg中音频格式有以下几种 , 每种格式有其占用的字节数信息

`libavutil/samplefmt.h`

> ```c++
> enum AVSampleFormat {
>     AV_SAMPLE_FMT_NONE = -1,
>     AV_SAMPLE_FMT_U8,          ///< unsigned 8 bits
>     AV_SAMPLE_FMT_S16,         ///< signed 16 bits
>     AV_SAMPLE_FMT_S32,         ///< signed 32 bits
>     AV_SAMPLE_FMT_FLT,         ///< float
>     AV_SAMPLE_FMT_DBL,         ///< double
> 
>     AV_SAMPLE_FMT_U8P,         ///< unsigned 8 bits, planar
>     AV_SAMPLE_FMT_S16P,        ///< signed 16 bits, planar
>     AV_SAMPLE_FMT_S32P,        ///< signed 32 bits, planar
>     AV_SAMPLE_FMT_FLTP,        ///< float, planar
>     AV_SAMPLE_FMT_DBLP,        ///< double, planar
>     AV_SAMPLE_FMT_S64,         ///< signed 64 bits
>     AV_SAMPLE_FMT_S64P,        ///< signed 64 bits, planar
> 
>     AV_SAMPLE_FMT_NB           ///< Number of sample formats. DO 																		NOT USE if linking dynamically
> };
> ```

## 3.3 分片(plane)和打包(packed)

- plane : 以双声道为例 , 带P (plane) 的数据格式在存储时 , 其左声道和右声道的数据是分开存储的 , 左声道的数据存储在data[0] , 右声道的数据存储在data[1] , 每个声道的所占⽤的字节数为linesize[0]和 linesize[1]
- packed : 不带P (packed) 的音频数据在存储时 , 是按照LRLRLR...的格式交替存储在data[0]中 , linesize[0]表示总的数据量

## 3.4 声道分布(channel_layout)

声道分布在 `\libavutil\channel_layout.h` 中有定义 , ⼀般来说用的比较多的是 `AV_CH_LAYOUT_STEREO` (双声道) 和 `AV_CH_LAYOUT_SURROUND` (三声道) , 这两者的定义如下 : 

> ```c++
> #define AV_CH_LAYOUT_STEREO (AV_CH_FRONT_LEFT|AV_CH_FRONT_RIGHT)
> #define AV_CH_LAYOUT_SURROUND (AV_CH_LAYOUT_STEREO|AV_CH_FRONT_CENTER)
> ```

## 3.5 音频帧的数据量计算

⼀帧音频的数据量(字节) =  channel数 × nb_samples样本数 × 每个样本占用的字节数

audio_frame_data_size = channel × nb_samples × sizeof(sample_type)

如果该音频帧是FLTP格式的PCM数据 , 包含1024个样本 , 双声道 , 那么该音频帧包含的音频数据量是 2 * 1024 * 4 = 8192字节

`AV_SAMPLE_FMT_DBL : 2 × 1024 × 8 = 16384`

## 3.6 音频播放时间计算

以采样率44100Hz来计算 , 每秒44100个sample , 而正常⼀帧为1024个sample , 可知每帧播放时间 ÷ 1024 = 1000ms ÷ 44100 , 得到每帧播放时间 = 1024 × 1000 ÷ 44100=23.2ms (更精确的是23.21995464852608) 

公式 : ⼀帧播放时间(毫秒) =  nb_samples样本数 × 1000 ÷ 采样率

例子 : 

(1) 1024 × 1000 ÷ 44100 = 23.21995464852608ms ->约等于23.2ms , 精度损失了 0.01995464852608ms , 如果累计10万帧 , 误差 > 1995毫秒 , 如果有视频⼀起的就会有音频同步的问题 , 如果按着23.2去计算pts (0 23.2 46.4) 就会有累积误差

(2) 1024 × 1000 ÷ 48000 = 21.33333333333333ms

# 4. FFmpeg重采样API

- 分配音频重采样的上下⽂
  - `struct SwrContext *swr_alloc(void);`
- 当设置好相关的参数后 , 使用此函数来初始化SwrContext结构体
  - `int swr_init(struct SwrContext *s);`
- 分配SwrContext并设置 / 重置常用的参数

> ```c++
> struct SwrContext *swr_alloc_set_opts(struct SwrContext *s, 
>                                    // 音频重采样上下⽂
>                                     int64_t out_ch_layout, 
>                                    // 输出的layout,如:5.1声道
> 									enum AVSampleFormat out_sample_fmt, 
>                                    // 输出的采样格式。Float, S16,⼀般选⽤是s16 绝⼤部分声卡⽀持
> 									int out_sample_rate, 
>                                    //输出采样率
> 									int64_t in_ch_layout, 
>                                    //输⼊的layout
> 									enum AVSampleFormat in_sample_fmt, 
>                                    // 输⼊的采样格式
> 									int in_sample_rate, 
>                                    // 输⼊的采样率
> 									int log_offset, 
>                                    // ⽇志相关,不⽤管先,直接为0
> 									void *log_ctx
>                                    // ⽇志相关,不⽤管先,直接为NULL
>                                      );
> // struct SwrContext *s 如果是NULL,则返回一个新的带设置的SwrContext对象
> // struct SwrContext *s 如果是非空,那么会重置传入的SwrContext对象里的设置,然后把新的设置写入传入的SwrContext对象里
> ```

- 将输⼊的音频按照定义的参数进行转换并输出

> ```c++
> int swr_convert(struct SwrContext *s, 
>                 // 音频重采样的上下⽂
> 				uint8_t **out, 
>                 // 输出的指针,传递的输出的数组
> 				int out_count, 
>                 //输出的样本数量,不是字节数,单通道的样本数量
> 				const uint8_t **in , 
>                 //输⼊的数组,AVFrame解码出来的DATA
> 				int in_count 
>                 //输⼊的单通道的样本数量
> );
> 
> /*
> 返回值 <= out_count
> **in 设置为NULL 和 in_count可以设置为0 , 以最后刷新最后⼏个样本
> 
> */
> 
> in_count × 1000 ÷ in_sample_rate = out_count × 1000 ÷ out_sample_rate
> 
> in_count ÷ in_sample_rate = out_count ÷ out_sample_rate
>  
> out_count = in_count ÷ in_sample_rate × out_sample_rate
> 
> in_count = out_count ÷ out_sample_rate × in_sample_rate
> 
> */
> ```

- 释放掉SwrContext结构体并将此结构体置为NULL
  - `void swr_free(struct SwrContext **s)`
- 音频重采样 , 采样格式转换和混合库

> ```tex
> 与lswr的交互是通过SwrContext完成的,SwrContext被分配给swr_alloc()或swr_alloc_set_opts()它是不透明的,所以所有参数必须使⽤AVOptions API设置,为了使⽤lswr,你需要做的第⼀件事就是分配SwrContext,这可以使⽤swr_alloc()或swr_alloc_set_opts()来完成,如果您使⽤前者,则必须通过AVOptions API设置选项,后⼀个函数提供了相同的功能,但它允许您在同⼀语句中设置⼀些常⽤选项
> ```

例如 , 以下代码将设置 **$\color{red}{\mathbf{从平面浮动样本格式到交织的带符号16位整数的转换}}$**，从48kHz到44.1kHz的下采样 , 以及从5.1声道到立体声的下混合 (使用默认混合矩阵) , 这是使用 `swr_alloc(...)`函数

> ```c++
> SwrContext *swr = swr_alloc();
> 
> av_opt_set_channel_layout(swr, "in_channel_layout", AV_CH_LAYOUT_5POINT1, 0);
> 
> av_opt_set_channel_layout(swr, "out_channel_layout", AV_CH_LAYOUT_STEREO, 0);
> 
> av_opt_set_int(swr, "in_sample_rate", 48000, 0);
> 
> av_opt_set_int(swr, "out_sample_rate", 44100, 0);
> 
> av_opt_set_sample_fmt(swr, "in_sample_fmt", AV_SAMPLE_FMT_FLTP, 0);
> 
> av_opt_set_sample_fmt(swr, "out_sample_fmt", AV_SAMPLE_FMT_S16, 0);
> ```

同样的工作也可以使用 `swr_alloc_set_opts(...)` : 

> ```c++
> SwrContext *swr = swr_alloc_set_opts(NULL, 
>                                   		// we're allocating a new context
> 									AV_CH_LAYOUT_STEREO, 
>                                      // out_ch_layout
> 									AV_SAMPLE_FMT_S16, 
>                                      // out_sample_fmt
> 									44100, 
>                                      // out_sample_rate
> 									AV_CH_LAYOUT_5POINT1, 
>                                      // in_ch_layout
> 									AV_SAMPLE_FMT_FLTP, 
>                                      // in_sample_fmt
>                                     	48000, 
>                                      // in_sample_rate
> 									0, 
>                                      // log_offset
> 									NULL); 
> 									// log_ctx
> ```

⼀旦设置了所有值 , 它必须用 `swr_init(...)` 初始化 ,  如果需要更改转换参数 , 可以使用AVOptions来更改参数 , 如上面第⼀个例⼦所述; 或者使用 `swr_alloc_set_opts(...)` , 但是第⼀个参数是分配的上下文 , 您必须再次调用 `swr_init(...)`

转换本身通过重复调用 `swr_convert(...)` 来完成 , 请注意 , 如果提供的输出空间不⾜或采样率转换完成后 , 样本可能会在swr中缓冲 , 这需要"未来"样本 ,  可以随时通过使用 `swr_convert(...)` ( `in_count` 可以设置为0 ) 来检索不需要将来输入的样本 , 在转换结束时 , 可以通过调用具有NULL in 和 `in incount` 的 `swr_convert(...)` 来刷新重采样缓冲区

# 5. ⾳频重采样工程范例

## 5.1 简单范例(resample)

FFMpeg自带的resample例子 : `FFmpeg\doc\examples\resampling_audio.c` , 这里把最核心的resample代码贴一下 , 在工程中使用时 , 注意设置的各种参数 , 给定的输入数据都不能错

[[参考工程]](/code/win/2-FFmpeg/10-audio_resample)

> ```c++
> #include <iostream>
> #include <fstream>
> 
> extern "C"
> {
> #include <libavutil/opt.h>
> #include <libavutil/channel_layout.h>
> #include <libavutil/samplefmt.h>
> #include <libswresample/swresample.h>
> }
> 
> template<typename F>
> struct Destroyer final{
>        Destroyer(const Destroyer&) = delete;
>        Destroyer& operator=(const Destroyer&) = delete;
>        explicit Destroyer(F &&f):fn(std::move(f)){}
>        ~Destroyer() {
>            fn();
>        }
> private:
>       const F fn;
> };
> 
> static std::string av_get_err(const int& errnum)
> {
>        constexpr auto ERROR_STRING_SIZE {1024};
>        char err_buf[ERROR_STRING_SIZE]{};
>        av_strerror(errnum, err_buf, std::size(err_buf));
>        return {err_buf};
> }
> 
> static int get_format_from_sample_fmt(const char **fmt,
>                                          const AVSampleFormat &sample_fmt)
> {
> 
>        struct sample_fmt_entry {
>            AVSampleFormat sample_fmt; const char *fmt_be, *fmt_le;
>        } sample_fmt_entries[] = {
>            { AV_SAMPLE_FMT_U8,  "u8",    "u8"    },
>            { AV_SAMPLE_FMT_S16, "s16be", "s16le" },
>            { AV_SAMPLE_FMT_S32, "s32be", "s32le" },
>            { AV_SAMPLE_FMT_FLT, "f32be", "f32le" },
>            { AV_SAMPLE_FMT_DBL, "f64be", "f64le" },
>        };
> 
>        for (const auto &entry : sample_fmt_entries){
>            if (sample_fmt == entry.sample_fmt) {
>                *fmt = AV_NE(entry.fmt_be, entry.fmt_le);
>                return 0;
>            }
>        }
>    
>     std::cerr << "Sample format :" << av_get_sample_fmt_name(sample_fmt) <<
>            " not supported as output format\n";
>        return AVERROR(EINVAL);
>    }
>    
>    
>    /**
>  * Fill dst buffer with nb_samples, generated starting from t. 交错模式的
>     */
>    static void fill_samples(double *dst,const int &nb_samples,const int &nb_channels, const int &sample_rate, double &t)
>    {
>        const auto tincr {1.0 / sample_rate};
>     constexpr auto c {2 * M_PI * 440.0};
> 
>     for (int i{};i < nb_samples;++i){
>         dst[0] = sin(c * t);
>         for(int j{1};j < nb_channels;++j){
>             dst[j] = dst[0];
>         }
>         dst += nb_channels;
>         t += tincr;
>     }
> }
> 
> int main(const int argc,const char* argv[]) {
> 
>     if (argc < 2) {
>         std::cerr << "Usage: " << argv[1] <<  " output_file\n";
>         return -1;
>     }
> 
>     std::ofstream dst_filename(argv[1]);
>     /*
>      * 输入参数
>      */
>     //constexpr auto src_ch_layout{AV_CH_LAYOUT_STEREO};
>     constexpr AVChannelLayout src_ch_layout AV_CHANNEL_LAYOUT_STEREO;
>     constexpr auto src_rate {48000};
>     constexpr auto src_sample_fmt {AV_SAMPLE_FMT_DBL};
>     constexpr auto src_nb_channels{src_ch_layout.nb_channels};
>     uint8_t **src_data{};
>     int src_linesize{};
>     constexpr auto src_nb_samples {1024};
> 
>     /*
>      * 输出参数
>      */
>     //constexpr auto dst_ch_layout {AV_CH_LAYOUT_STEREO};
>     constexpr AVChannelLayout dst_ch_layout AV_CHANNEL_LAYOUT_STEREO;
>     constexpr auto dst_rate {44100};
>     constexpr auto dst_sample_fmt {AV_SAMPLE_FMT_S16};
>     constexpr auto dst_nb_channels {dst_ch_layout.nb_channels};
>     uint8_t **dst_data {};
>     int dst_linesize{};
>     int64_t dst_nb_samples{},max_dst_nb_samples{};
> 
>     SwrContext *swr_ctx{};
> 
>     Destroyer d{std::move([&]() {
>         if (dst_filename) {
>             dst_filename.close();
>         }
>         if (src_data) {
>             av_freep(&src_data[0]);
>             av_freep(&src_data);
>         }
>         if (dst_data) {
>             av_freep(&dst_data[0]);
>             av_freep(&dst_data);
>         }
>         swr_free(&swr_ctx);
>         std::cerr << "destory complete\n";
>     })};
> 
>     // 创建重采样器
>     /* create resampler context */
>     swr_ctx = swr_alloc();
>     if (!(swr_ctx)) {
>         std::cerr << "swr_alloc faild\n";
>         return -1;
>     }
> 
>     // 设置重采样参数
>     /* set options */
>     // 输入参数
>     av_opt_set_chlayout(swr_ctx,"in_chlayout",&src_ch_layout,0);
>     av_opt_set_int(swr_ctx, "in_sample_rate",src_rate, 0);
>     av_opt_set_sample_fmt(swr_ctx, "in_sample_fmt",src_sample_fmt, 0);
>     // 输出参数
>     av_opt_set_chlayout(swr_ctx, "out_chlayout",&dst_ch_layout, 0);
>     av_opt_set_int(swr_ctx, "out_sample_rate",dst_rate, 0);
>     av_opt_set_sample_fmt(swr_ctx, "out_sample_fmt", dst_sample_fmt, 0);
> 
>    // 初始化重采样
>    // /* initialize the resampling context */
>     auto ret{swr_init(swr_ctx)};
>     if (ret < 0) {
>         std::cerr << "Failed to initialize the resampling context : " << av_get_err(ret) << "\n";
>         return -1;
>     }
>     // 给输入源分配内存空间
>     ret = av_samples_alloc_array_and_samples(&src_data,&src_linesize,src_nb_channels,src_nb_samples,src_sample_fmt,0);
>     if (ret < 0) {
>         std::cerr << "Could not allocate source samples\n";
>         return -1;
>     }
> 
>     /* compute the number of converted samples: buffering is avoided
>     * ensuring that the output buffer will contain at least all the
>     * converted input samples
>     */
>     // 计算输出采样数量
>     max_dst_nb_samples = dst_nb_samples =
>         av_rescale_rnd(src_nb_samples, dst_rate, src_rate, AV_ROUND_UP);
>     // 分配输出缓存内存
>     ret = av_samples_alloc_array_and_samples(&dst_data,&dst_linesize,dst_nb_channels,static_cast<int>(dst_nb_samples),dst_sample_fmt,0);
>     if (ret < 0){
>         std::cerr << "Could not allocate destination samples\n";
>         return -1;
>     }
> 
>     double t{};
>     int dst_bufsize{};
>     do{
>         fill_samples(reinterpret_cast<double*>(src_data[0]), src_nb_samples, src_nb_channels, src_rate, t);
>         /* compute destination number of samples */
>         const auto delay{swr_get_delay(swr_ctx, src_rate)};
>         dst_nb_samples = av_rescale_rnd(delay + src_nb_samples, dst_rate, src_rate, AV_ROUND_UP);
> 
>         if (dst_nb_samples > max_dst_nb_samples){
>             av_freep(&dst_data[0]);
>             ret = av_samples_alloc(dst_data, &dst_linesize, dst_nb_channels,static_cast<int>(dst_nb_samples), dst_sample_fmt, 1);
>             if (ret < 0){
>                 std::cerr << "av_samples_alloc failed : " << av_get_err(ret) << "\n";
>                 break;
>             }
> 
>             max_dst_nb_samples = dst_nb_samples;
>         }
> 
>         const auto ret_len { swr_convert(swr_ctx, dst_data, static_cast<int>(dst_nb_samples),
>                           const_cast<const uint8_t**>(src_data), src_nb_samples)};
>         if (ret_len < 0){
>             std::cerr << "Error while converting\n";
>             return -1;
>         }
> 
>         dst_bufsize = av_samples_get_buffer_size(&dst_linesize, dst_nb_channels,ret_len, dst_sample_fmt, 1);
> 
>         if (dst_bufsize < 0) {
>             std::cerr << "Could not get sample buffer size\n";
>             return -1;
>         }
> 
>         std::cout << "t: " << t << " in: " << src_nb_samples << " out: " << ret_len << "\n";
>         dst_filename.write(reinterpret_cast<const std::ostream::char_type*>(dst_data[0]),dst_bufsize);
> 
>     }while (t < 10);
> 
>     ret = swr_convert(swr_ctx, dst_data, static_cast<int>(dst_nb_samples), nullptr, 0);
>     if (ret < 0) {
>         fprintf(stderr, "Error while converting\n");
>         return -1;
>     }
> 
>     dst_bufsize = av_samples_get_buffer_size(&dst_linesize, dst_nb_channels,
>                                              ret, dst_sample_fmt, 1);
>     if (dst_bufsize < 0) {
>         fprintf(stderr, "Could not get sample buffer size\n");
>         return -1;
>     }
>     
>     std::cout << "flush in: 0 out: " << ret << "\n";
>     
>     dst_filename.write(reinterpret_cast<const std::ostream::char_type*>(dst_data[0]),dst_bufsize);
> 
>     const char *fmt{};
>     if ((ret = get_format_from_sample_fmt(&fmt, dst_sample_fmt)) < 0){
>         return -1;
>     }
> 
>     std::cerr << "Resampling succeeded. Play the output file with the command:\n" <<
>             "ffplay -f " << fmt << " -channel_layout " << dst_ch_layout.u.mask << " -channels " << dst_nb_channels << " -ar " << dst_rate <<
>             " " << argv[1] << "\n";
>     
>     return 0;
> }
> ```



## 5.2 复杂范例

结合AVAudioFifo进行封装 , 本范例采用C++封装

[[参考工程]](/code/win/2-FFmpeg/11-audio_resample_2)

此处展示重采样器的部分代码,详细实现请查参考工程链接

> ```c++
> #include <iostream>
> 
> extern "C"{
> #include <libavutil/opt.h>
> #include <libavutil/avutil.h>
> #include <libavutil/frame.h>
> #include <libavcodec/avcodec.h>
> }
> 
> #include "Audio_Resampler.h"
> #include "AVAudioFifo_t.h"
> #include "SwrContext_t.h"
> #include "AVHelper.h"
> 
> namespace rsmp {
> 
>     bool Audio_Resampler::construct() noexcept{
> 
>         m_src_channels = m_Resampler_Params.dst_ch_layout.nb_channels;
>         m_dst_channels = m_Resampler_Params.dst_ch_layout.nb_channels;
> 
>         try{
>             m_audio_fifo = AVAudioFifo_t::create(m_Resampler_Params.dst_sample_fmt,
>                                                  m_dst_channels,1);
>         }catch (const std::exception &e){
>             std::cerr << "AVAudioFifo construct failed " << e.what() << "\n";
>             return {};
>         }
> 
>         if (m_Resampler_Params) {
>             m_is_fifo_only.store(true);
>             return true;
>         }
> 
>         try{
>             m_swr_ctx = SwrContext_t::create();
>         }catch (const std::exception &e){
>             std::cerr << "SwrContext construct failed " << e.what() << "\n";
>             return {};
>         }
>         av_opt_set_in();
>         av_opt_set_out();
> 
>         if (!m_swr_ctx->init()){
>             std::cerr << "failed to initialize the resampling context.\n";
>             m_audio_fifo.reset();
>             m_swr_ctx.reset();
>             destory_resampled_data();
>             return {};
>         }
> 
>         if (!init_resampled_data()){
>             std::cerr << "alloc resampled_data failed\n";
>             m_audio_fifo.reset();
>             m_swr_ctx.reset();
>             destory_resampled_data();
>             return {};
>         }
> 
>         std::cout << "construct done\n" << std::flush;
> 
>         return true;
>     }
> 
>     std::shared_ptr<Audio_Resampler> Audio_Resampler::create(const Audio_Resampler_Params & params){
> 
>         try{
>            std::shared_ptr<Audio_Resampler> obj{new Audio_Resampler(params)};
>             if (!obj->construct()) {
>                 obj.reset();
>                 throw std::runtime_error("Audio_Resampler init failed\n");
>             }
>             return obj;
>         }catch (const std::bad_alloc &e){
>             std::cerr << e.what() << "\n";
>             throw std::runtime_error("Audio_Resampler construct failed\n");
>         }
>     }
> 
>     Audio_Resampler::Audio_Resampler(const Audio_Resampler_Params &params):
>     m_Resampler_Params{params} {
> 
>     }
> 
>     bool Audio_Resampler::init_resampled_data(){
>         /*在发送的时候可能遇到空间不足情况,需重新申请,重新申请之前,先释放原来的空间*/
>         destory_resampled_data();
>         int linesize{};
>         const auto ret {av_samples_alloc_array_and_samples(&m_resampled_data,
>                                                             &linesize, m_dst_channels,
>                                                      static_cast<int>(m_resampled_data_size),
>                                                                 m_Resampler_Params.dst_sample_fmt,
>                                                                 0)};
> 
>         return ret < 0 ? (std::cerr << "fail accocate audio resampled data buffer errcode : " <<
>             ret << "\t" << AVHelper::av_get_err(ret) << "\n",false):true;
>     }
> 
>     void Audio_Resampler::destory_resampled_data(){
>         if (m_resampled_data){
>             av_freep(&m_resampled_data[0]);
>             av_freep(&m_resampled_data);
>         }
>     }
> 
>     void Audio_Resampler::av_opt_set_in() const {
>         (void)m_swr_ctx->opt_set_chlayout("in_channel_layout",&m_Resampler_Params.src_ch_layout);
>         (void)m_swr_ctx->opt_set_sample_fmt("in_sample_fmt",m_Resampler_Params.src_sample_fmt);
>         (void)m_swr_ctx->opt_set_rate("in_sample_rate",m_Resampler_Params.src_sample_rate);
>     }
> 
>     void Audio_Resampler::av_opt_set_out() const{
>         (void)m_swr_ctx->opt_set_chlayout("out_channel_layout",&m_Resampler_Params.dst_ch_layout);
>         (void)m_swr_ctx->opt_set_sample_fmt("out_sample_fmt",m_Resampler_Params.dst_sample_fmt);
>         (void)m_swr_ctx->opt_set_rate("out_sample_rate",m_Resampler_Params.dst_sample_rate);
>     }
> 
>     AVFrame * Audio_Resampler::alloc_out_frame(const int &nb_samples) const{
> 
>         auto frame {av_frame_alloc()};
> 
>         if (frame) {
>             frame->nb_samples = nb_samples;
>             frame->ch_layout = m_Resampler_Params.dst_ch_layout;
>             frame->format = m_Resampler_Params.dst_sample_fmt;
>             frame->sample_rate = m_Resampler_Params.dst_sample_rate;
>             const auto ret{av_frame_get_buffer(frame, 0)};
>             /*根据提供的信息分配相对应的数据空间*/
>             if (ret < 0) {
>                 av_frame_free(&frame);
>                 std::cerr << "cannot allocate audio data buffer : " << ret << "\t" <<
>                 AVHelper::av_get_err(ret) << "\n";
>             }
>         }
> 
>         return frame;
>     }
> 
>     int Audio_Resampler::fifo_read_helper(uint8_t **out_data, const int &need_nb_samples, int64_t &pts) {
> 
>         const auto read_size {m_audio_fifo->read(reinterpret_cast<void**>(out_data),need_nb_samples)};
> 
>         if (read_size < 0) {
>             std::cerr << "avaudio_fifo_read failed errcode : " << read_size << "\t" <<
>                 AVHelper::av_get_err(read_size) << "\n";
>             return read_size;
>         }
> 
>         pts = m_cur_pts;
>         m_cur_pts += need_nb_samples;
>         m_total_resampled_num += need_nb_samples;
> 
>         return read_size;
>     }
> 
>     int Audio_Resampler::need_samples_num(const int &nb_samples) const {
> 
>         const auto _fifo_size{fifo_size()};
> 
>         const auto need_nb_samples{!nb_samples ? _fifo_size : nb_samples};
>         /*参数nb_samples为0,则尝试查看fifo有多数数据*/
>         if (_fifo_size < need_nb_samples || !need_nb_samples) {
>             /*如果fifo为0或fifo数据量小于需要的数据量,则退出当前函数*/
>             std::cerr << "Not enough data or fifo is empty\n";
>             return {};
>         }
> 
>         return need_nb_samples;
>     }
> 
>     Audio_Resampler::~Audio_Resampler(){
>         destory_resampled_data();
>     }
> 
>     int Audio_Resampler::send_frame(const AVFrame& frame) {
> 
>         const auto src_data{frame.extended_data};     //输入源的buffer
>         const auto src_nb_samples{frame.nb_samples};// 输入源采样点数量
>         const auto pts{frame.pts};
> 
>         return send_frame(src_data,src_nb_samples,pts);
>     }
> 
>     int Audio_Resampler::send_frame(uint8_t** const in_data, const int& in_nb_samples, const int64_t& pts){
> 
>         const auto src_data{in_data};
>         const auto src_nb_samples{in_nb_samples};
> 
>         if (src_data){
>             if (AV_NOPTS_VALUE == m_start_pts && AV_NOPTS_VALUE != pts) {
>                 m_start_pts = pts;
>                 m_cur_pts = pts;
>             }
>         }else{
>             m_is_flushed.store(true);
>         }
> 
>         if (m_is_fifo_only){
>             return src_data ? m_audio_fifo->write(reinterpret_cast<void**>(src_data),src_nb_samples) : 0;
>         }
> 
>         // 计算这次做重采样能够获取到的重采样后的点数
>         const auto delay {m_swr_ctx->get_delay(m_Resampler_Params.src_sample_rate)};
> 
>         const auto dst_nb_samples{av_rescale_rnd(delay + src_nb_samples,m_Resampler_Params.dst_sample_rate,
>             m_Resampler_Params.src_sample_rate,AV_ROUND_UP)};
> 
>         if (dst_nb_samples > m_resampled_data_size){
>             m_resampled_data_size = dst_nb_samples;
>             if (!init_resampled_data()){
>                 return AVERROR(ENOMEM);
>             }
>         }
> 
>         const auto convert_nb_samples{m_swr_ctx->convert(m_resampled_data,static_cast<int>(dst_nb_samples),
>                                                          const_cast<const uint8_t**>(src_data),src_nb_samples)};
> 
>         const auto w_nb{m_audio_fifo->write(reinterpret_cast<void**>(m_resampled_data),convert_nb_samples)};
> 
>         if (w_nb < 0){
>             std::cerr << "av_audio_fifo_write failed errcode : "<< w_nb << "\t" << AVHelper::av_get_err(w_nb) << "\n";
>         }
> 
>         return w_nb;
>     }
> 
>     int Audio_Resampler::send_frame(const uint8_t* in_data, const int& in_bytes, const int64_t& pts){
> 
>         AVFrame frame{};
>         frame.format = m_Resampler_Params.src_sample_fmt;
>         frame.ch_layout = m_Resampler_Params.src_ch_layout;
>         const auto sample_fmt_size{av_get_bytes_per_sample(m_Resampler_Params.src_sample_fmt)};
>         /*输入的数据数量 ÷ 每个样本的字节数(样本格式大小) ÷ 通道数 */
>         frame.nb_samples = in_bytes / sample_fmt_size / frame.ch_layout.nb_channels;
>         frame.pts = pts;
> 
>         avcodec_fill_audio_frame(&frame, frame.ch_layout.nb_channels,
>                              m_Resampler_Params.src_sample_fmt, in_data,
>                              in_bytes, 0);
> 
>         return send_frame(frame);
>     }
> 
>     AVFrame* Audio_Resampler::receive_frame(const int& nb_samples){
> 
>         const auto need_nb_samples{need_samples_num(nb_samples)};
>         if (!need_nb_samples) {
>             return {};
>         }
> 
>         auto frame {alloc_out_frame(need_nb_samples)};
> 
>         if (frame) {
>             if (fifo_read_helper(frame->extended_data,need_nb_samples, frame->pts) < 0) {
>                 av_frame_free(&frame);
>             }
>         }
> 
>         return frame;
>     }
> 
>     int Audio_Resampler::receive_frame(uint8_t** out_data, const int& nb_samples, int64_t& pts){
> 
>         if (!out_data) {
>             std::cerr << "out_data is empty\n";
>             return AVERROR(ENOMEM);
>         }
> 
>         const auto need_nb_samples{need_samples_num(nb_samples)};
>         if (!need_nb_samples) {
>             return {};
>         }
> 
>         return fifo_read_helper(out_data, need_nb_samples, pts);
>     }
> 
>     int Audio_Resampler::fifo_size() const{
>         return m_audio_fifo->size();
>     }
> 
>     int64_t Audio_Resampler::start_pts() const{
>         return m_start_pts;
>     }
> 
>     int64_t Audio_Resampler::cur_pts() const{
>         return m_cur_pts;
>     }
> }
> 
> ```



