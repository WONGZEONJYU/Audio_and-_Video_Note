# 1. 重点问题

如何进⾏重采样?

采样率不⼀样的时候pts怎么处理?

[[官⽅参考⽂档]](http://ffmpeg.org/doxygen/trunk/group__lswr.html)

# 2. 重采样

## 2.1 什么是重采样

所谓的重采样 , 就是改变音频的 **$\color{red}{\mathbf{采样率、sample\ format、声道数等参数}}$** , 使之按照我们期望的参数输出

## 2.2 为什么要重采样

为什么要重采样?当然是原有的音频参数不满⾜我们的需求 , 比如在FFmpeg解码音频的时候 , 不同的音源有不同的格式 , 采样率等 , 在解码后的数据中的这些参数也会不⼀致 ( 最新FFmpeg 解码音频后 , 音频格式为 `AV_SAMPLE_FMT_FLTP` , 这个参数应该是⼀致的 ) , 如果我们接下来需要使⽤解码后的音频数据做其他操作 , 而这些参数的不⼀致导致会有很多额外工作 , 此时直接对其进行重采样 , 获取我们制定的音频参数 , 这样就会方便很多
再比如在将⾳频进⾏SDL播放时候 , 因为当前的SDL2.0不支持planar格式 , 也不支持浮点型的⽽最新的FFMPEG 16年会将音频解码为`AV_SAMPLE_FMT_FLTP` 格式 , 因此此时就需要我们对其重采样 , 使之可以在SDL2.0上进⾏播放

## 2.3 可调节的参数

通过重采样 , 我们可以对 :

1. **$\color{red}{\mathbf{sample\ rate(采样率)}}$**
2. **$\color{red}{\mathbf{sample\ format(采样格式)}}$**
3. **$\color{red}{\mathbf{channel\ layout(通道布局,可以通过此参数获取声道数)}}$**

# 3. 对应参数解析

## 3.1 采样率

采样设备每秒抽取样本的次数

## 3.2采样格式及量化精度(位宽)

每种⾳频格式有不同的量化精度 (位宽) , 位数越多 , 表示值就越精确 , 声音表现自然就越精准。FFMpeg中音频格式有以下几种 , 每种格式有其占用的字节数信息

`libavutil/samplefmt.h`

> ```c++
> enum AVSampleFormat {
>     AV_SAMPLE_FMT_NONE = -1,
>     AV_SAMPLE_FMT_U8,          ///< unsigned 8 bits
>     AV_SAMPLE_FMT_S16,         ///< signed 16 bits
>     AV_SAMPLE_FMT_S32,         ///< signed 32 bits
>     AV_SAMPLE_FMT_FLT,         ///< float
>     AV_SAMPLE_FMT_DBL,         ///< double
> 
>     AV_SAMPLE_FMT_U8P,         ///< unsigned 8 bits, planar
>     AV_SAMPLE_FMT_S16P,        ///< signed 16 bits, planar
>     AV_SAMPLE_FMT_S32P,        ///< signed 32 bits, planar
>     AV_SAMPLE_FMT_FLTP,        ///< float, planar
>     AV_SAMPLE_FMT_DBLP,        ///< double, planar
>     AV_SAMPLE_FMT_S64,         ///< signed 64 bits
>     AV_SAMPLE_FMT_S64P,        ///< signed 64 bits, planar
> 
>     AV_SAMPLE_FMT_NB           ///< Number of sample formats. DO 																		NOT USE if linking dynamically
> };
> ```

## 3.3 分⽚(plane)和打包(packed)

- plane : 以双声道为例 , 带P (plane) 的数据格式在存储时 , 其左声道和右声道的数据是分开存储的 , 左声道的数据存储在data[0] , 右声道的数据存储在data[1] , 每个声道的所占⽤的字节数为linesize[0]和 linesize[1]
- packed : 不带P (packed) 的音频数据在存储时 , 是按照LRLRLR...的格式交替存储在data[0]中 , linesize[0]表示总的数据量

## 3.4 声道分布(channel_layout)

声道分布在 `\libavutil\channel_layout.h` 中有定义 , ⼀般来说用的比较多的是 `AV_CH_LAYOUT_STEREO` (双声道) 和 `AV_CH_LAYOUT_SURROUND` (三声道) , 这两者的定义如下 : 

> ```c++
> #define AV_CH_LAYOUT_STEREO (AV_CH_FRONT_LEFT|AV_CH_FRONT_RIGHT)
> #define AV_CH_LAYOUT_SURROUND (AV_CH_LAYOUT_STEREO|AV_CH_FRONT_CENTER)
> ```

## 3.5 音频帧的数据量计算

⼀帧音频的数据量(字节) =  channel数 × nb_samples样本数 × 每个样本占用的字节数

audio_frame_data_size = channel × nb_samples × sizeof(sample_type)

如果该音频帧是FLTP格式的PCM数据 , 包含1024个样本 , 双声道 , 那么该音频帧包含的音频数据量是 2 * 1024 * 4 = 8192字节

`AV_SAMPLE_FMT_DBL : 2 × 1024 × 8 = 16384`

## 3.6 音频播放时间计算

以采样率44100Hz来计算 , 每秒44100个sample , 而正常⼀帧为1024个sample , 可知每帧播放时间 ÷ 1024 = 1000ms ÷ 44100 , 得到每帧播放时间 = 1024 × 1000 ÷ 44100=23.2ms (更精确的是23.21995464852608) 

公式 : ⼀帧播放时间(毫秒) =  nb_samples样本数 × 1000 ÷ 采样率

例子 : 

(1) 1024 × 1000 ÷ 44100 = 23.21995464852608ms ->约等于23.2ms , 精度损失了 0.01995464852608ms , 如果累计10万帧 , 误差 > 1995毫秒 , 如果有视频⼀起的就会有音频同步的问题 , 如果按着23.2去计算pts (0 23.2 46.4) 就会有累积误差

(2) 1024 × 1000 ÷ 48000 = 21.33333333333333ms

# 4. FFmpeg重采样API

- 分配音频重采样的上下⽂
  - `struct SwrContext *swr_alloc(void);`
- 当设置好相关的参数后 , 使用此函数来初始化SwrContext结构体
  - `int swr_init(struct SwrContext *s);`
- 分配SwrContext并设置 / 重置常用的参数

> ```c++
> struct SwrContext *swr_alloc_set_opts(struct SwrContext *s, 
>                                    // 音频重采样上下⽂
>                                     int64_t out_ch_layout, 
>                                    // 输出的layout,如:5.1声道
> 									enum AVSampleFormat out_sample_fmt, 
>                                    // 输出的采样格式。Float, S16,⼀般选⽤是s16 绝⼤部分声卡⽀持
> 									int out_sample_rate, 
>                                    //输出采样率
> 									int64_t in_ch_layout, 
>                                    //输⼊的layout
> 									enum AVSampleFormat in_sample_fmt, 
>                                    // 输⼊的采样格式
> 									int in_sample_rate, 
>                                    // 输⼊的采样率
> 									int log_offset, 
>                                    // ⽇志相关,不⽤管先,直接为0
> 									void *log_ctx
>                                    // ⽇志相关,不⽤管先,直接为NULL
>                                      );
> // struct SwrContext *s 如果是NULL,则返回一个新的带设置的SwrContext对象
> // struct SwrContext *s 如果是非空,那么会重置传入的SwrContext对象里的设置,然后把新的设置写入传入的SwrContext对象里
> ```

- 将输⼊的音频按照定义的参数进行转换并输出

> ```c++
> int swr_convert(struct SwrContext *s, 
>                 // 音频重采样的上下⽂
> 				uint8_t **out, 
>                 // 输出的指针,传递的输出的数组
> 				int out_count, 
>                 //输出的样本数量,不是字节数,单通道的样本数量
> 				const uint8_t **in , 
>                 //输⼊的数组,AVFrame解码出来的DATA
> 				int in_count 
>                 //输⼊的单通道的样本数量
> );
> 
> /*
> 返回值 <= out_count
> **in 设置为NULL 和 in_count可以设置为0 , 以最后刷新最后⼏个样本
> 
> */
> 
> in_count × 1000 ÷ in_sample_rate = out_count × 1000 ÷ out_sample_rate
> 
> in_count ÷ in_sample_rate = out_count ÷ out_sample_rate
>  
> out_count = in_count ÷ in_sample_rate × out_sample_rate
> 
> in_count = out_count ÷ out_sample_rate × in_sample_rate
> 
> */
> ```

- 释放掉SwrContext结构体并将此结构体置为NULL
  - `void swr_free(struct SwrContext **s)`
- 音频重采样 , 采样格式转换和混合库

> ```tex
> 与lswr的交互是通过SwrContext完成的,SwrContext被分配给swr_alloc()或swr_alloc_set_opts()它是不透明的,所以所有参数必须使⽤AVOptions API设置,为了使⽤lswr,你需要做的第⼀件事就是分配SwrContext,这可以使⽤swr_alloc()或swr_alloc_set_opts()来完成,如果您使⽤前者,则必须通过AVOptions API设置选项,后⼀个函数提供了相同的功能,但它允许您在同⼀语句中设置⼀些常⽤选项
> ```

例如 , 以下代码将设置 **$\color{red}{\mathbf{从平面浮动样本格式到交织的带符号16位整数的转换}}$**，从48kHz到44.1kHz的下采样 , 以及从5.1声道到立体声的下混合 (使用默认混合矩阵) , 这是使用 `swr_alloc(...)`函数

> ```c++
> SwrContext *swr = swr_alloc();
> 
> av_opt_set_channel_layout(swr, "in_channel_layout", AV_CH_LAYOUT_5POINT1, 0);
> 
> av_opt_set_channel_layout(swr, "out_channel_layout", AV_CH_LAYOUT_STEREO, 0);
> 
> av_opt_set_int(swr, "in_sample_rate", 48000, 0);
> 
> av_opt_set_int(swr, "out_sample_rate", 44100, 0);
> 
> av_opt_set_sample_fmt(swr, "in_sample_fmt", AV_SAMPLE_FMT_FLTP, 0);
> 
> av_opt_set_sample_fmt(swr, "out_sample_fmt", AV_SAMPLE_FMT_S16, 0);
> ```

同样的工作也可以使用 `swr_alloc_set_opts(...)` : 

> ```c++
> SwrContext *swr = swr_alloc_set_opts(NULL, 
>                                   		// we're allocating a new context
> 									AV_CH_LAYOUT_STEREO, 
>                                      // out_ch_layout
> 									AV_SAMPLE_FMT_S16, 
>                                      // out_sample_fmt
> 									44100, 
>                                      // out_sample_rate
> 									AV_CH_LAYOUT_5POINT1, 
>                                      // in_ch_layout
> 									AV_SAMPLE_FMT_FLTP, 
>                                      // in_sample_fmt
>                                     	48000, 
>                                      // in_sample_rate
> 									0, 
>                                      // log_offset
> 									NULL); 
> 									// log_ctx
> ```

⼀旦设置了所有值 , 它必须用 `swr_init(...)` 初始化 ,  如果需要更改转换参数 , 可以使用AVOptions来更改参数 , 如上面第⼀个例⼦所述; 或者使用 `swr_alloc_set_opts(...)` , 但是第⼀个参数是分配的上下文 , 您必须再次调用 `swr_init(...)`

转换本身通过重复调用 `swr_convert(...)` 来完成 , 请注意 , 如果提供的输出空间不⾜或采样率转换完成后 , 样本可能会在swr中缓冲 , 这需要"未来"样本 ,  可以随时通过使用 `swr_convert(...)` ( `in_count` 可以设置为0 ) 来检索不需要将来输入的样本 , 在转换结束时 , 可以通过调用具有NULL in 和 `in incount` 的 `swr_convert(...)` 来刷新重采样缓冲区

# 5. ⾳频重采样工程范例

## 5.1 简单范例(resample)

FFMpeg自带的resample例子 : `FFmpeg\doc\examples\resampling_audio.c` , 这里把最核心的resample代码贴一下 , 在工程中使用时 , 注意设置的各种参数 , 给定的输入数据都不能错

[[参考工程]](/code/win/2-FFmpeg/10-audio_resample)

> ```c++
> #include <iostream>
> #include <fstream>
> 
> extern "C"
> {
> #include <libavutil/opt.h>
> #include <libavutil/channel_layout.h>
> #include <libavutil/samplefmt.h>
> #include <libswresample/swresample.h>
> }
> 
> template<typename F>
> struct Destroyer final{
>     Destroyer(const Destroyer&) = delete;
>     Destroyer& operator=(const Destroyer&) = delete;
>     explicit Destroyer(F &&f):fn(std::move(f)){}
>     ~Destroyer() {
>         fn();
>     }
> private:
>    const F fn;
> };
> 
> static std::string av_get_err(const int& errnum)
> {
>     constexpr auto ERROR_STRING_SIZE {1024};
>     char err_buf[ERROR_STRING_SIZE]{};
>     av_strerror(errnum, err_buf, std::size(err_buf));
>     return {err_buf};
> }
> 
> static int get_format_from_sample_fmt(const char **fmt,
>                                       const AVSampleFormat &sample_fmt)
> {
> 
>     struct sample_fmt_entry {
>         AVSampleFormat sample_fmt; const char *fmt_be, *fmt_le;
>     } sample_fmt_entries[] = {
>         { AV_SAMPLE_FMT_U8,  "u8",    "u8"    },
>         { AV_SAMPLE_FMT_S16, "s16be", "s16le" },
>         { AV_SAMPLE_FMT_S32, "s32be", "s32le" },
>         { AV_SAMPLE_FMT_FLT, "f32be", "f32le" },
>         { AV_SAMPLE_FMT_DBL, "f64be", "f64le" },
>     };
> 
>     // for (int i {}; i < std::size(sample_fmt_entries); i++) {
>     //     const auto &entry {sample_fmt_entries[i]};
>     //     if (sample_fmt == entry.sample_fmt) {
>     //         *fmt = AV_NE(entry.fmt_be, entry.fmt_le);
>     //         return 0;
>     //     }
>     // }
> 
>     for (const auto &entry : sample_fmt_entries){
>         if (sample_fmt == entry.sample_fmt) {
>             *fmt = AV_NE(entry.fmt_be, entry.fmt_le);
>             return 0;
>         }
>     }
> 
>     fprintf(stderr,
>             "Sample format %s not supported as output format\n",
>             av_get_sample_fmt_name(sample_fmt));
>     return AVERROR(EINVAL);
> }
> 
> 
> /**
>  * Fill dst buffer with nb_samples, generated starting from t. 交错模式的
>  */
> static void fill_samples(double *dst,const int &nb_samples,const int &nb_channels, const int &sample_rate, double &t)
> {
>     const auto tincr {1.0 / sample_rate};
>     constexpr auto c {2 * M_PI * 440.0};
> 
>     for (int i{};i < nb_samples;++i){
>         dst[0] = sin(c * t);
>         for(int j{1};j < nb_channels;++j){
>             dst[j] = dst[0];
>         }
>         dst += nb_channels;
>         t += tincr;
>     }
> }
> 
> int main(const int argc,const char* argv[]) {
> 
>     if (argc < 2) {
>         std::cerr << "Usage: " << argv[1] <<  " output_file\n";
>         return -1;
>     }
> 
>     std::ofstream dst_filename(argv[1]);
>     /*
>      * 输入参数
>      */
>     //constexpr auto src_ch_layout{AV_CH_LAYOUT_STEREO};
>     constexpr AVChannelLayout src_ch_layout AV_CHANNEL_LAYOUT_STEREO;
>     constexpr auto src_rate {48000};
>     constexpr auto src_sample_fmt {AV_SAMPLE_FMT_DBL};
>     constexpr auto src_nb_channels{src_ch_layout.nb_channels};
>     uint8_t **src_data{};
>     int src_linesize{};
>     constexpr auto src_nb_samples {1024};
> 
>     /*
>      * 输出参数
>      */
>     //constexpr auto dst_ch_layout {AV_CH_LAYOUT_STEREO};
>     constexpr AVChannelLayout dst_ch_layout AV_CHANNEL_LAYOUT_STEREO;
>     constexpr auto dst_rate {44100};
>     constexpr auto dst_sample_fmt {AV_SAMPLE_FMT_S16};
>     constexpr auto dst_nb_channels {dst_ch_layout.nb_channels};
>     uint8_t **dst_data {};
>     int dst_linesize{};
>     int64_t dst_nb_samples{},max_dst_nb_samples{};
> 
>     SwrContext *swr_ctx{};
> 
>     const auto rres{[&]() {
>         if (dst_filename) {
>             dst_filename.close();
>         }
>         if (src_data) {
>             av_freep(&src_data[0]);
>             av_freep(&src_data);
>         }
>         if (dst_data) {
>             av_freep(&dst_data[0]);
>             av_freep(&dst_data);
>         }
>         swr_free(&swr_ctx);
>         std::cerr << "destory complete\n";
>     }};
> 
>     Destroyer d{std::move(rres)};
> 
>     // 创建重采样器
>     /* create resampler context */
>     swr_ctx = swr_alloc();
>     if (!(swr_ctx)) {
>         std::cerr << "swr_alloc faild\n";
>         return -1;
>     }
> 
>     // 设置重采样参数
>     /* set options */
>     // 输入参数
>     av_opt_set_chlayout(swr_ctx,"in_chlayout",&src_ch_layout,0);
>     av_opt_set_int(swr_ctx, "in_sample_rate",src_rate, 0);
>     av_opt_set_sample_fmt(swr_ctx, "in_sample_fmt",src_sample_fmt, 0);
>     // 输出参数
>     av_opt_set_chlayout(swr_ctx, "out_chlayout",&dst_ch_layout, 0);
>     av_opt_set_int(swr_ctx, "out_sample_rate",dst_rate, 0);
>     av_opt_set_sample_fmt(swr_ctx, "out_sample_fmt", dst_sample_fmt, 0);
> 
>    // 初始化重采样
>    // /* initialize the resampling context */
>     auto ret{swr_init(swr_ctx)};
>     if (ret < 0) {
>         std::cerr << "Failed to initialize the resampling context : " << av_get_err(ret) << "\n";
>         return -1;
>     }
>     // 给输入源分配内存空间
>     ret = av_samples_alloc_array_and_samples(&src_data,&src_linesize,src_nb_channels,src_nb_samples,src_sample_fmt,0);
>     if (ret < 0) {
>         std::cerr << "Could not allocate source samples\n";
>         return -1;
>     }
> 
>     /* compute the number of converted samples: buffering is avoided
>     * ensuring that the output buffer will contain at least all the
>     * converted input samples
>     */
>     // 计算输出采样数量
>     max_dst_nb_samples = dst_nb_samples =
>         av_rescale_rnd(src_nb_samples, dst_rate, src_rate, AV_ROUND_UP);
>     // 分配输出缓存内存
>     ret = av_samples_alloc_array_and_samples(&dst_data,&dst_linesize,dst_nb_channels,static_cast<int>(dst_nb_samples),dst_sample_fmt,0);
>     if (ret < 0){
>         std::cerr << "Could not allocate destination samples\n";
>         return -1;
>     }
> 
>     double t{};
>     int dst_bufsize{};
>     do{
>         fill_samples(reinterpret_cast<double*>(src_data[0]), src_nb_samples, src_nb_channels, src_rate, t);
>         /* compute destination number of samples */
>         const auto delay{swr_get_delay(swr_ctx, src_rate)};
>         dst_nb_samples = av_rescale_rnd(delay + src_nb_samples, dst_rate, src_rate, AV_ROUND_UP);
> 
>         if (dst_nb_samples > max_dst_nb_samples){
>             av_freep(&dst_data[0]);
>             ret = av_samples_alloc(dst_data, &dst_linesize, dst_nb_channels,static_cast<int>(dst_nb_samples), dst_sample_fmt, 1);
>             if (ret < 0){
>                 std::cerr << "av_samples_alloc failed : " << av_get_err(ret) << "\n";
>                 break;
>             }
> 
>             max_dst_nb_samples = dst_nb_samples;
>         }
> 
>         const auto ret_len { swr_convert(swr_ctx, dst_data, static_cast<int>(dst_nb_samples),
>                           const_cast<const uint8_t**>(src_data), src_nb_samples)};
>         if (ret_len < 0){
>             std::cerr << "Error while converting\n";
>             return -1;
>         }
> 
>         dst_bufsize = av_samples_get_buffer_size(&dst_linesize, dst_nb_channels,ret_len, dst_sample_fmt, 1);
> 
>         if (dst_bufsize < 0) {
>             std::cerr << "Could not get sample buffer size\n";
>             return -1;
>         }
> 
>         std::cout << "t: " << t << " in: " << src_nb_samples << " out: " << ret_len << "\n";
>         dst_filename.write(reinterpret_cast<const std::ostream::char_type*>(dst_data[0]),dst_bufsize);
> 
>     }while (t < 10);
> 
>     ret = swr_convert(swr_ctx, dst_data, static_cast<int>(dst_nb_samples), nullptr, 0);
>     if (ret < 0) {
>         fprintf(stderr, "Error while converting\n");
>         return -1;
>     }
> 
>     dst_bufsize = av_samples_get_buffer_size(&dst_linesize, dst_nb_channels,
>                                              ret, dst_sample_fmt, 1);
>     if (dst_bufsize < 0) {
>         fprintf(stderr, "Could not get sample buffer size\n");
>         return -1;
>     }
>     
>     std::cout << "flush in: 0 out: " << ret << "\n";
>     
>     dst_filename.write(reinterpret_cast<const std::ostream::char_type*>(dst_data[0]),dst_bufsize);
> 
>     const char *fmt{};
>     if ((ret = get_format_from_sample_fmt(&fmt, dst_sample_fmt)) < 0){
>         return -1;
>     }
> 
>     std::cerr << "Resampling succeeded. Play the output file with the command:\n" <<
>         "ffplay -f " << fmt << " -channel_layout " << dst_ch_layout.u.mask << " -channels " << dst_nb_channels << " -ar " << dst_rate <<
>             " " << argv[1] << "\n";
> 
>     return 0;
> }
> ```



## 5.2 复杂范例

结合AVAudioFifo进行封装