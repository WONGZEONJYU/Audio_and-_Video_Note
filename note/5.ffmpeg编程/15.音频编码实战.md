# 1. 音频编码流程

从本地文件读取PCM数据进行AAC格式编码 , 然后将编码后的AAC数据存储到本地⽂件 , 示例的流程如下所示 

<img src="assets/image-20240326160828318.png" alt="image-20240326160828318" /> 

## 1.1 关键函数说明 : 

- `avcodec_find_encoder(...)` : 根据指定的 `AVCodecID` 查找注册的编码器 
- `avcodec_alloc_context3(...)` : 为 `AVCodecContext` 分配内存
- `avcodec_open2(...)` : 打开编码器
- `avcodec_send_frame(...)` : 将 `AVFrame` 非压缩数据给编码器 
- `avcodec_receive_packet(...)` : 获取到编码后的 `AVPacket` 数据 , 收到的 packet 需要自己释放内存
- `av_frame_get_buffer(...)` : 为⾳频或视频帧分配新的buffer , 在调用这个函数之前 , 必须在AVFame上设置好以下属性 :
  - `format` (视频为像素格式 , 音频为样本格式)
  - `nb_samples` (样本个数，针对音频)
  - `channel_layout` (通道类型，针对音频)
  - `width/height` (宽高 , 针对视频) 
- `av_frame_make_writable(...)` 确保 `AVFrame` 是可写的 , 使用 `av_frame_make_writable(...)` 的问题是 , 在最坏的情况下 , 它会在您使⽤encode再次更改整个输⼊frame之前复制它 , 如果frame不可写 , `av_frame_make_writable(...)` 将分配新的缓冲区 , 并复制这个输入input frame数据 , 避免和编码器需要缓存该帧时造成冲突
- `av_samples_fill_arrays(...)` 填充音频帧 

## 1.2 对于 flush encoder的操作 

编码器通常的冲洗方法：调⽤⼀次 `avcodec_send_frame(NULL)` (返回成功)，然后不停调用 `avcodec_receive_packet(...)` 直到其返回 `AVERROR_EOF` , 取出所有缓存帧 , `avcodec_receive_packet(...)` 返回 `AVERROR_EOF` 这⼀次是没有有效数据的 , 仅仅获取到⼀个结束标志 

# 2. PCM样本格式

PCM (Pulse Code Modulation , 脉冲编码调制) 音频数据是未经压缩的音频采样数据裸流 , 它是由模拟信号经过采样、量化、编码转换成的标准数字音频数据

描述PCM数据的6个参数 : 

1. Sample Rate : 采样频率。8kHz(电话)、44.1kHz(CD)、48kHz(DVD) 
2. Sample Size : 量化位数。通常该值为16-bit
3. Number of Channels : 通道个数 , 常见的音频有立体声(stereo)和单声道(mono)两种类型 , 立体声包含左声道和右声道 , 另外还有环绕立体声等其它不太常⽤的类型 
4. Sign : 表示样本数据是否是有符号位 , 比如用⼀字节表示的样本数据 , 有符号的话表示范围为-128 ~127，⽆符号是0 ~ 255 ,有符号位16bits数据取值范围为 -32768~32767
5. Byte Ordering : 字节序 , 字节序是little-endian还是big-endian , 通常均为little-endian , 字节序说明见第4节
6. Integer Or Floating Point : 整形或浮点型 , 大多数格式的PCM样本数据使用整形表示 , 而在⼀些对精度要求高的应用方面，使用浮点类型表示PCM样本数据(浮点数 float值域为 [-1.0, 1.0]) 

推荐的PCM数据播放工具

- ffplay, 使用示例如下 

> ```bash
> #播放格式为f32le，双声道，采样频率48000Hz的PCM数据
> 2 ffplay -f f32le -ac 2 -ar 48000 pcm_audio
> ```

- [[Audacity]](https://www.audacityteam.org/) : 一款免费开源的跨平台音频处理软件
- Adobe Auditon : 导⼊原始数据 , 打开的时候需要选择采样率、格式和字节序 

# 3. FFmpeg支持的PCM数据格式

使用 ffmpeg -formats命令 , 获取ffmpeg支持的音视频格式 , 其中我们可以找到支持的PCM格式

> ```tex
> DE alaw PCM A-law
> DE f32be PCM 32-bit floating-point big-endian
> DE f32le PCM 32-bit floating-point little-endian
> DE f64be PCM 64-bit floating-point big-endian
> DE f64le PCM 64-bit floating-point little-endian
> DE mulaw PCM mu-law
> DE s16be PCM signed 16-bit big-endian
> DE s16le PCM signed 16-bit little-endian
> DE s24be PCM signed 24-bit big-endian
> DE s24le PCM signed 24-bit little-endian
> DE s32be PCM signed 32-bit big-endian
> DE s32le PCM signed 32-bit little-endian
> DE s8 PCM signed 8-bit
> DE u16be PCM unsigned 16-bit big-endian
> DE u16le PCM unsigned 16-bit little-endian
> DE u24be PCM unsigned 24-bit big-endian
> DE u24le PCM unsigned 24-bit little-endian
> DE u32be PCM unsigned 32-bit big-endian
> DE u32le PCM unsigned 32-bit little-endian
> DE u8 PCM unsigned 8-bit
> 
> s是有符号,u是⽆符号,f是浮点数,be是⼤端,le是⼩端
> ```

# 4. FFmpeg中Packed 和 Planar的PCM数据区别

FFmpeg中音视频数据基本上都有Packed和Planar两种存储⽅式 , 对于双声道音频来说 : 

- Packed方式为两个声道的数据交错存储
- Planar方式为两个声道分开存储

假设⼀个L/R为⼀个采样点 , 数据存储的方式如下所示 : 

补充 : 如果一帧是1024个samples  , 对于 Packed 就是1024个L 1024个R交错存放

对于 Planar , 先存1024个L , 然后再存1024个R

- Packed: L R L R L R L R  
- Planar: L L L L ... R R R R...  

## 4.1 packed格式

> ```tex
> AV_SAMPLE_FMT_U8, ///< unsigned 8 bits
> 2 AV_SAMPLE_FMT_S16, ///< signed 16 bits
> 3 AV_SAMPLE_FMT_S32, ///< signed 32 bits
> 4 AV_SAMPLE_FMT_FLT, ///< float
> 5 AV_SAMPLE_FMT_DBL, ///< double
> ```

**$\color{red}{\mathbf{只能保存在AVFrame的uint8\_t *data[0]}}$**

⾳频保持格式 : 

```
LRLRLR...
```

## 4.2 planar格式

planar为FFmpeg内部存储音频使用的采样格式 , 所有的Planar格式后面都有字母P标识

> ```tex
> AV_SAMPLE_FMT_U8P, ///< unsigned 8 bits, planar
> AV_SAMPLE_FMT_S16P, ///< signed 16 bits, planar
> AV_SAMPLE_FMT_S32P, ///< signed 32 bits, planar
> AV_SAMPLE_FMT_FLTP, ///< float, planar
> AV_SAMPLE_FMT_DBLP, ///< double, planar
> AV_SAMPLE_FMT_S64, ///< signed 64 bits
> AV_SAMPLE_FMT_S64P, ///< signed 64 bits, planar
> 
> plane 0: LLLLLLLLLLLLLLLLLLLLLLLLLL...
> plane 1: RRRRRRRRRRRRRRRRRRRRRRRRRR...
> ```

**$\color{red}{\mathbf{plane\ 0\ 对于\ uint8\_t *data[0]}}$**
**$\color{red}{\mathbf{plane\ 1\ 对于\ uint8\_t *data[1]}}$**

FFmpeg默认的AAC编码器不支持 `AV_SAMPLE_FMT_S16` 格式的编码，只支持 `AV_SAMPLE_FMT_FLTP` , 这种格式是按平面存储 , 样点是float类型 , 所谓平面也就是 每个声道单独存储 :

- 左声道存储到data[0]中
- 右声道存储到data[1]中

FFmpeg音频 **$\color{red}{\mathbf{解码后}}$** 和 **$\color{red}{\mathbf{编码前}}$​** 的数据是存放在AVFrame结构中的

- Packed格式 , `frame.data[0]` 或 `frame.extended_data[0]` 包含所有的音频数据中 
- Planar格式 , `frame.data[i]` 或者 `frame.extended_data[i]` 表示第 i个声道的数据 (假设声道0是第一个) , `AVFrame.data`数组大小固定为8 , 如果声道数超过8 , 需要从 `frame.extended_data` 获取声道数据  

# 5. 补充说明

- Planar模式是 ffmpeg内部存储模式 , 我们实际使用的音频文件都是Packed模式的
- FFmpeg解码不同格式的音频输出的音频采样格式不是⼀样
  - 测试发现，其中AAC解码输出的数据为浮点型的 `AV_SAMPLE_FMT_FLTP` 格式 , MP3解码输出的数据为`AV_SAMPLE_FMT_S16P` 格式 (使用的MP3文件为16位深) 
  - 具体采样格式可以查看解码后的 `AVFrame` 中的 **$\color{red}{\mathbf{format成员}}$** 或 编解码器的 `AVCodecContext` 中的 **$\color{red}{\mathbf{sample\_fmt成员}}$** 

- Planar或者Packed模式直接影响到保存文件时写文件的操作 , 操作数据的时候⼀定要先检测音频采样格式

# 6. PCM字节序

> ```tex
> 谈到字节序的问题,必然牵涉到两⼤CPU派系。那就是Motorola的PowerPC系列CPU和Intel的x86系列CPU。PowerPC系列采⽤big endian⽅式存储数据,⽽x86系列则采⽤little endian⽅式存储数据,那么究竟什么是big endian,什么⼜是little endian?
> big endian是指低地址存放最⾼有效字节(MSB,Most Significant Bit),⽽little endian则是低地址存放最低有效字节(LSB,Least Significant Bit)
> 下⾯⽤图像加以说明,⽐如数字0x12345678在两种不同字节序CPU中的存储顺序如下所示:
> ----------------------------------------------------------------------------------------------------->
> Big Endian
> 低地址 		⾼地址
> | 12 | 34 | 56 | 78 |
> ----------------------------------------------------------------------------------------------------->
> Little Endian
> 低地址 		⾼地址
> | 78 | 56 | 34 | 12 |
> 
> 所有⽹络协议都是采⽤big endian的⽅式来传输数据的,所以也把big endian⽅式称之为⽹络字节序,当两台采⽤不同字节序的主机通信时,在发送数据之前都必须经过字节序的转换成为⽹络字节序后再进⾏传输
> ```

# 7. 作业

`avcodec_receive_packet(...)` 不同的返回值代表什么含义;读取的packet如果要放到队列里面那应该怎么放到队列?

# 8. 编程实验

[[参考工程]](/code/win/2-FFmpeg/12-encode_audio)

> ```c++
> 
> extern "C"{
> #include <libavcodec/avcodec.h>
> //#include <libavcodec/codec.h>
> //#include <libavcodec/codec_id.h>
> #include <libavformat/avformat.h>
> }
> 
> #include <iostream>
> #include <fstream>
> #include <memory_resource>
> 
> static std::string av_get_err(const int& errnum)
> {
>     char err_buf[1024]{};
>     av_strerror(errnum, err_buf, sizeof(err_buf));
>     return {err_buf};
> }
> 
> /* 检测该编码器是否支持该采样格式 */
> static bool check_sample_fmt(const AVCodec *codec, const AVSampleFormat &sample_fmt)
> {
>     // 通过AV_SAMPLE_FMT_NONE作为结束符
>     for(auto p {codec->sample_fmts};*p != AV_SAMPLE_FMT_NONE;++p){
>         if (sample_fmt == *p){
>             return true;
>         }
>     }
> 
>     return {};
> }
> 
> /* 检测该编码器是否支持该采样率 */
> static bool check_sample_rate(const AVCodec *codec, const int &sample_rate)
> {
>     // 0作为退出条件,比如libfdk-aacenc.c的aac_sample_rates
>     for(auto p {codec->supported_samplerates};*p;++p){
>         std::cout << codec->name << " support " << *p << "hz\n";
>         if (*p == sample_rate){
>             return true;
>         }
>     }
> 
>     return {};
> }
> 
> /* 检测该编码器是否支持该通道布局, 该函数只是作参考 */
> static bool check_channel_layout(const AVCodec *codec, const AVChannelLayout &channel_layout)
> {
>     // 不是每个codec都给出支持的channel_layout
>     auto p{codec->ch_layouts};
> 
>     if(!p) {
>         std::cout << "the codec " << codec->name << " no set channel_layouts\n";
>         return true;
>     }
> 
>     for(;p->u.mask;++p){
>         std::cout << codec->name << " support channel_layout " << p->u.mask << "\n";
>         if (p->u.mask == channel_layout.u.mask){
>             return true;
>         }
>     }
> 
>     return {};
> }
> 
> static void get_adts_header(const AVCodecContext *ctx, uint8_t *adts_header,const int &aac_length)
> {
>     int freq_idx ;    //0: 96000 Hz  3: 48000 Hz 4: 44100 Hz
>     switch (ctx->sample_rate) {
>         case 96000: freq_idx = 0; break;
>         case 88200: freq_idx = 1; break;
>         case 64000: freq_idx = 2; break;
>         case 48000: freq_idx = 3; break;
>         case 44100: freq_idx = 4; break;
>         case 32000: freq_idx = 5; break;
>         case 24000: freq_idx = 6; break;
>         case 22050: freq_idx = 7; break;
>         case 16000: freq_idx = 8; break;
>         case 12000: freq_idx = 9; break;
>         case 11025: freq_idx = 10; break;
>         case 8000: freq_idx = 11; break;
>         case 7350: freq_idx = 12; break;
>         default: freq_idx = 4; break;
>     }
> 
>     const auto chanCfg {ctx->ch_layout.nb_channels};
>     const auto frame_length {aac_length + 7};
>     adts_header[0] = 0xFF;
>     adts_header[1] = 0xF1;
>     adts_header[2] = (ctx->profile << 6) + (freq_idx << 2) + (chanCfg >> 2);
>     adts_header[3] = ((chanCfg & 3) << 6) + (frame_length  >> 11);
>     adts_header[4] = (frame_length & 0x7FF) >> 3;
>     adts_header[5] = ((frame_length & 7) << 5) + 0x1F;
>     adts_header[6] = 0xFC;
> }
> 
> static int encode(AVCodecContext &ctx,const AVFrame &frame, AVPacket &pkt, std::ofstream &output)
> {
>     /* send the frame for encoding */
> 
>     auto ret {frame.extended_data ? avcodec_send_frame(&ctx, &frame) : avcodec_send_frame(&ctx, nullptr)};
> 
>     if (ret < 0) {
>         std::cout << "Error sending the frame to the encoder\n";
>         return -1;
>     }
> 
>     /* read all the available output packets (in general there may be any number of them */
>     // 编码和解码都是一样的,都是send 1次,然后receive多次, 直到AVERROR(EAGAIN)或者AVERROR_EOF
>     for(;;) {
>         ret = avcodec_receive_packet(&ctx, &pkt);
>         if (AVERROR(EAGAIN) == ret || AVERROR_EOF == ret ) {
>             return 0;
>         } else if (ret < 0) {
>             std::cerr << "Error encoding audio frame\n";
>             return -1;
>         }else{
>         }
> 
>         //printf("ctx->flags:0x%x & AV_CODEC_FLAG_GLOBAL_HEADER:0x%x, name:%s\n",ctx.flags, ctx.flags & AV_CODEC_FLAG_GLOBAL_HEADER, ctx.codec->name);
>         const auto has_header{ctx.flags & AV_CODEC_FLAG_GLOBAL_HEADER};
>         std::cout << "ctx->flags:0x" << std::hex << ctx.flags << " & AV_CODEC_FLAG_GLOBAL_HEADER:0x" <<
>             std::hex << has_header << ", name:" << ctx.codec->name << "\n";
> 
>         if(has_header) {
>             // 需要额外的adts header写入
>             uint8_t aac_header[7]{};
>             get_adts_header(&ctx, aac_header, pkt.size);
>             const auto prv_len{output.tellp()};
>             //len = fwrite(aac_header, 1, 7, output);
>             output.write(reinterpret_cast<const char*>(aac_header),7);
>             //const auto len{output.tellp() - prv_len};
>             if( 7 != output.tellp() - prv_len ) {
>                 std::cerr << "fwrite aac_header failed\n";
>                 return -1;
>             }
>         }
> 
>         const auto prv_len{output.tellp()};
>         output.write(reinterpret_cast<const char*>(pkt.data),pkt.size);
>         //const auto len{output.tellp() - prv_len};
>         if(output.tellp() - prv_len != pkt.size) {
>             std::cerr << "fwrite aac data failed\n";
>             return -1;
>         }
> 
>         /* 是否需要释放数据?avcodec_receive_packet第一个调用的就是 av_packet_unref
>         * 所以我们不用手动去释放,这里有个问题,不能将pkt直接插入到队列,因为编码器会释放数据
>         * 可以新分配一个pkt, 然后使用av_packet_move_ref转移pkt对应的buffer
>         */
>         // av_packet_unref(pkt);
>     }
>     //return -1;
> }
> 
> static void f32le_convert_to_fltp(const float *f32le, float *fltp,const int &nb_samples) {
>     float *fltp_l = fltp;   // 左通道
>     float *fltp_r = fltp + nb_samples;   // 右通道
>     for(int i {}; i < nb_samples; i++) {
>         fltp_l[i] = f32le[i * 2];     // 0 1   - 2 3
>         fltp_r[i] = f32le[i * 2 + 1];   // 可以尝试注释左声道或者右声道听听声音
>     }
> }
> 
> template<typename F>
> struct Destroyer final{
>     Destroyer(const Destroyer&) = delete;
>     Destroyer& operator=(const Destroyer&) = delete;
>     explicit Destroyer(F &&f):fn(std::move(f)){}
>     ~Destroyer() {
>         fn();
>     }
> private:
>     const F fn;
> };
> 
> /*xxx.exe xxx_FMT_S16.pcm xxx.aac libfdk_aac*/
> /*xxx.exe xxx_FMT_FLTP.pcm xxx.aac aac*/
> /*libfdk_aac只支持S16*/
> 
> int main(const int argc,const char* argv[])
> {
>     if (argc < 3){
>         std::cerr << "Usage: " << argv[0] << " <input_file out_file [codec_name]>, argc:" << argc << "\n";
>         return -1;
>     }
> 
>     std::pmr::unsynchronized_pool_resource mptool;
>     std::ifstream in_file(argv[1],std::ios::binary);
>     std::ofstream out_file(argv[2],std::ios::binary);
> 
>     constexpr auto codec_id {AV_CODEC_ID_AAC};
>     const AVCodec * codec{};
>     AVCodecContext *codec_ctx{};
>     AVPacket *pkt{};
>     AVFrame *frame{};
>     uint8_t* pcm_buf{},*pcm_tmp_buf{};
>     std::size_t one_frame_size{};
> 
>     bool force_{};
>     std::string code_name;
>     if (4 == argc){
>         if (std::string("libfdk_aac") == argv[3] || std::string("aac") == argv[3]){
>             force_ = true;
>             code_name = argv[3];
>         }else{
>             code_name = "aac";
>         }
>     }
> 
>      const Destroyer d([&](){
> 
>         if (pcm_tmp_buf){
>             mptool.deallocate(pcm_tmp_buf,one_frame_size);
>         }
>         if (pcm_buf){
>             mptool.deallocate(pcm_buf,one_frame_size);
>         }
>         av_frame_free(&frame);
>         av_packet_free(&pkt);
>         avcodec_free_context(&codec_ctx);
>         out_file.close();
>         in_file.close();
>         std::cerr << "finish\n";
>     });
> 
>     if (!in_file){
>         std::cerr << "open in_file failed\n";
>         return -1;
>     }
> 
>     if (!out_file){
>         std::cerr << "open out_file failed\n";
>         return -1;
>     }
> 
>     if (force_){
>         std::cout << "force codec name: " << code_name << "\n";
>         codec = avcodec_find_encoder_by_name(code_name.c_str());
>     }else{
>         codec = avcodec_find_encoder(codec_id);
>         std::cout << "default codec name: aac \n";
>     }
> 
>     if (!codec){
>         std::cerr << "Codec not found\n";
>         return -1;
>     }
> 
>     codec_ctx = avcodec_alloc_context3(codec);
>     if (!codec_ctx){
>         std::cerr << "avcodec_alloc_context3 failed\n";
>         return -1;
>     }
> 
>     codec_ctx->codec_id = codec_id;
>     codec_ctx->codec_type = AVMEDIA_TYPE_AUDIO;
>     codec_ctx->sample_rate = 48000;
>     codec_ctx->ch_layout = AV_CHANNEL_LAYOUT_STEREO;
>     codec_ctx->profile = FF_PROFILE_AAC_LOW;
> 
>     if(std::string("libfdk_aac") == codec->name) {
>         codec_ctx->sample_fmt = AV_SAMPLE_FMT_S16;
>     } else {
>         codec_ctx->sample_fmt = AV_SAMPLE_FMT_FLTP;
>     }
> 
>     if (!check_channel_layout(codec,codec_ctx->ch_layout)){
>         std::cerr << "Encoder does not support channel layout " << codec_ctx->ch_layout.u.mask << "\n";
>         return -1;
>     }
> 
>     if (!check_sample_fmt(codec,codec_ctx->sample_fmt)){
>         std::cerr << "Encoder does not support sample format " <<
>             av_get_sample_fmt_name(codec_ctx->sample_fmt) << "\n";
>         return -1;
>     }
> 
>     if (!check_sample_rate(codec,codec_ctx->sample_rate)){
>         std::cerr << "Encoder does not support sample rate " << codec_ctx->sample_rate << "\n";
>         return -1;
>     }
> 
>     codec_ctx->flags = AV_CODEC_FLAG_GLOBAL_HEADER;  //ffmpeg默认的aac是不带adts，而fdk_aac默认带adts，这里我们强制不带
> 
>     std::cout << "frame size = " << codec_ctx->frame_size << "\n";
> 
>     if (avcodec_open2(codec_ctx,codec,nullptr) < 0){
>         std::cerr << "avcodec_open2 failed\n";
>         return -1;
>     }
> 
>     std::cout << "frame size = " << codec_ctx->frame_size << "\n";
>     std::cout << "\n\nAudio encode config\n";
>     std::cout << "channels : " << codec_ctx->ch_layout.nb_channels << "\n";
>     std::cout << "sample_rate : " << codec_ctx->sample_rate << "\n";
>     std::cout << "sample_format : " << codec_ctx->sample_fmt << "\n";
> 
>     pkt = av_packet_alloc();
>     if (!pkt) {
>         std::cerr << "av_packet_alloc failed\n";
>         return -1;
>     }
> 
>     frame = av_frame_alloc();
>     if (!frame) {
>         std::cerr << "av_frame_alloc failed\n";
>         return -1;
>     }
> 
>     frame->nb_samples = codec_ctx->frame_size;
>     frame->format = codec_ctx->sample_fmt;
>     frame->ch_layout = codec_ctx->ch_layout;
> 
>     if (av_frame_get_buffer(frame,0) < 0) {
>         std::cerr << "Could not allocate audio data buffers\n";
>         return -1;
>     }
>     /*calc one_frame_size*/
>     const auto format_size{av_get_bytes_per_sample(static_cast<AVSampleFormat>(frame->format))};
>     one_frame_size = frame->nb_samples * format_size * frame->ch_layout.nb_channels;
> 
>     try {
>         pcm_buf = static_cast<uint8_t *>(mptool.allocate(one_frame_size));
>     } catch (std::exception &e) {
>         std::cout << "alloc pcm_buf failed : " << e.what() << "\n";
>         return -1;
>     }
> 
>     const auto is_FMT_S16{AV_SAMPLE_FMT_S16 == frame->format};
> 
>     if (!is_FMT_S16) {
>         try {
>             pcm_tmp_buf = static_cast<uint8_t *>(mptool.allocate(one_frame_size));
>         } catch (std::exception &e) {
>             std::cout << "alloc pcm_buf failed : " << e.what() << "\n";
>             return -1;
>         }
>     }
> 
>     int64_t pts {};
>     std::cout << "start enode\n";
> 
>     for(;;) {
>         std::fill_n(pcm_buf,one_frame_size,0);
>         try {
>             in_file.read(reinterpret_cast<char *>(pcm_buf),static_cast<std::streamsize>(one_frame_size));
>             if (in_file.eof()) {
>                 std::cerr << "read finish\n";
>                 break;
>             }
>         } catch (std::exception &e) {
>             std::cerr << "read failed " << e.what() << "\n";
>             return -1;
>         }
> 
>         /* 确保该frame可写,如果编码器内部保持了内存参考计数,则需要重新拷贝一个备份
>             目的是新写入的数据和编码器保存的数据不能产生冲突*/
>         if (av_frame_make_writable(frame) < 0) {
>             std::cerr << "av_frame_make_writable\n";
>         }
> 
>         if (is_FMT_S16) {
>             // 将读取到的PCM数据填充到frame去，但要注意格式的匹配, 是planar还是packed都要区分清楚
>             if(av_samples_fill_arrays(frame->data,frame->linesize,pcm_buf,
>                    frame->ch_layout.nb_channels,
>                    frame->nb_samples,static_cast<AVSampleFormat>(frame->format),0) < 0) {
>                 std::cerr << "1 av_samples_fill_arrays failed\n";
>                 return -1;
>             }
> 
>         }else {
>             // 将本地的f32le packed模式的数据转为float palanar
>             std::fill_n(pcm_tmp_buf,one_frame_size,0);
>             f32le_convert_to_fltp(reinterpret_cast<const float *>(pcm_buf),reinterpret_cast<float *>(pcm_tmp_buf),frame->nb_samples);
>             if(av_samples_fill_arrays(frame->data,frame->linesize,pcm_tmp_buf,
>                             frame->ch_layout.nb_channels,
>                             frame->nb_samples,static_cast<AVSampleFormat>(frame->format),0) < 0) {
>                 std::cerr << "2 av_samples_fill_arrays failed\n";
>                 return -1;
>             }
>         }
> 
>         // 设置pts
>         pts += frame->nb_samples;
>         frame->pts = pts;       // 使用采样率作为pts的单位，具体换算成秒 pts*1/采样率
>         if (encode(*codec_ctx,*frame,*pkt,out_file) < 0) {
>             std::cerr << "encode failed\n";
>             break;
>         }
>     }
> 
>     encode(*codec_ctx, {}, *pkt, out_file);
>     return 0;
> }
> 
> ```



