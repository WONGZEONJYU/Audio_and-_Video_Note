# 1. NALU (Network Abstract Layer Unit)

⾳视频编码在流媒体和⽹络领域占有重要地位 ; 流媒体编解码流程⼤致如下图所示 : 

<img src="assets/image-20240202145538530.png" alt="image-20240202145538530" style="zoom:150%;" /> 

# 2. H264简介

H.264从1999年开始 , 到2003年形成草案 , 最后在2007年定稿有待核实。在ITU的标准⾥称为H.264 , 在MPEG的标准⾥是MPEG-4的⼀个组成部分 MPEG-4 Part 10 , ⼜叫Advanced Video Codec , 因此常常称为MPEG-4 AVC或直接叫AVC  

# 3. H264 编解码解析  

阅读完H264/AVC 编解码器的介绍 , 脑海中仅仅是留下下面三条 : 

* H264并没有明白规定一个编解码器怎样实现 , 仅仅是规定了一个编码后的视频比特流的句法 , 和该比特流的解码方法 , 这个与MPEG 类似
* H264和曾经的标准 (如H261、H263、MPEG-1、MPEG-4) 的编解码器实现流程没有太大差别 , 基本的不同在于各功能块的细节
* H264就是利用实现的复杂性获得压缩性能的明显改善 (至于复杂度的评估 , 以后会介绍)

以下介绍一下H264的编码器框图 : 

<img src="assets/70.png" alt="img" style="zoom:150%;" /> 

> ```tex
> 编码器採用的仍是变换和预測的混合编码法。在图6.1中,输入的帧或场Fn以宏块为单位被编码器处理。首先,按帧内或者帧间预測编码的方法进行处理。假设採用帧间预测编码,其预測值PRED是由当前片中前面已编码的參考图像(F’n-1)经运动补偿(MC)后得到,当中參考图像用F’n-1表示。预測值PRED和当前块相减后,产生一个残差块Dn,经块变换、量化后产生一组量化后的变换系数X,再经熵编码,与解码所需的一些头信息一起组成压缩后的码流,经NAL(网络自适应层)供传输和存储用
> ```

专有名词解释 : [[宏块]](https://baike.baidu.com/item/%E5%AE%8F%E5%9D%97/4183514?fr=ge_ala) [[Motion compensation(运动补偿)]](https://en.wikipedia.org/wiki/Motion_compensation) [[Motion Estimation(运动估计)]](https://en.wikipedia.org/wiki/Motion_estimation)

- 帧间编码 (inter-frame coding) : 在帧间编码中 , 一帧图像的压缩是通过与其前后相邻的帧进行比较来实现的。这种方法能够进一步减小视频数据的冗余 , 提高压缩效率 , 但也增加了解码的复杂度。
- 帧内编码 (intra-frame coding) : 与帧间编码相反 , 帧内编码是通过在单个图像帧内部实现压缩 , 使用该帧自身的信息来减小数据冗余。尽管压缩效率相对较低 , 但解码过程更为简单

H264的解码器框图 : 

<img src="assets/70-1706858400520-3.png" alt="img" style="zoom:150%;" /> 

> ```tex
> 在图6.2中,将编码器的NAL输出的H264比特流经熵解码得到量化后的一组变换系数X,再经反量化、反变换，得到残差D’n。利用从该比特流中解码出的头信息,解码器就产生一个预測块PRED,它和编码器中的原始PRED是同样的。当该解码器产生的PRED与残差D’n相加后,就得到了uF’n,再经滤波后,最后就得到滤波后的解码输出图像F’n
> ```

# 4. H264编码原理

在⾳视频传输过程中 , 视频⽂件的传输是⼀个极大的问题 ; ⼀段分辨率为1920 × 1080 , 每个像素点为RGB占⽤3个字节 , 帧率是25的视频 , 对于传输带宽的要求是 : 1920 ×1080 × 3 × 25 ÷ 1024 ÷ 1024 =148.315MB/s , 换成bps则意味着视频每秒带宽为
1186.523Mbps , 这样的速率对于网络存储是不可接受的。因此视频压缩和编码技术应运而生 , 对于视频⽂件来说 , 视频由单张图⽚帧所组成 , 比如每秒25帧 , 但是图片帧的像素块之间存在相似性 , 因此视频帧图像可以进⾏图像压缩 ; H264采用了16 ×16的分块大小对 , 视频帧图像进行相似比较和压缩编码 , 如下图所示 :

<img src="assets/image-20240202154950380.png" alt="image-20240202154950380" /> 

# 5. H264中的I帧、P帧和B帧

H26使⽤帧内压缩和帧间压缩的⽅式提高编码压缩率 ; H264采⽤了独特的I帧、P帧和B帧策略来实现 , 连续帧之间的压缩  

<img src="assets/image-20240202155234606.png" alt="image-20240202155234606" /> 

如上图所示 

| 帧的分类 | 中⽂                                                         | 意义                                                         |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| I帧      | 帧内编码帧 <br />intra picture                               | I 帧通常是每个 GOP (MPEG 所使⽤的⼀种视频压缩技术) 的第⼀个帧 , 经过适度地压缩 , 做为随机访问的参考点 , 可以当成图象。I帧可以看成是⼀个图像经过压缩后的产物。 ⾃身可以通过视频解压算法解压成⼀张单独的完整的图⽚ |
| P帧      | 前向预测编码帧 <br />predictive-frame                        | 通过充分将低于图像序列中前⾯已编码帧的时间冗余信息来 压缩传输数据量的编码图像，也叫预测帧。 需要参考其前⾯的⼀个I frame 或者P frame来⽣成⼀张完整的图⽚ |
| B帧      | 双向预测帧 <br />bi-directional interpolated prediction frame | 既考虑与源图像序列前面已编码帧 , 也顾及源图像序列后⾯已编码帧之间的时间冗余信息来压缩传输数据量的编码图像, 也叫双向预测帧。 则要参考其前⼀个I或者P帧及其后⾯的⼀个P帧来⽣成⼀张完整的图⽚ |

**$\color{red}{\mathbf{ 压缩率 B > P > I}}$**

# 6. H264编码结构解析

H264除了实现了对视频的压缩处理之外 , 为了⽅便⽹络传输 , 提供了对应的视频编码和分片策略；类似于⽹络数据封装成IP帧 , 在H264中将其称为组 (**GOP** , group of pictures)、片(slice)、宏块(Macroblock) 这些⼀起组成了H264的码流分层结构 ; H264将其组织成为序列(GOP)、图片(Pictrue)、片(Slice)、宏块(Macroblock)、子块(subblock)五个层次。GOP (图像组) 主要⽤作形容⼀个IDR帧 到下⼀个IDR帧之间的间隔了多少个帧  

<img src="assets/image-20240202160558338.png" alt="image-20240202160558338" /> 

H264将视频分为连续的帧进行传输 , 在连续的帧之间使用I帧、P帧和B帧。同时对于帧内而言 , 将图像分块为片、宏块和字块进行分片传输 ; 通过这个过程实现对视频⽂件的压缩包装

## 6.1 IDR

**IDR** (Instantaneous Decoding Refresh , 即时解码刷新) **$\color{red}{\mathbf{⼀个序列的第⼀个图像叫做 IDR 图像}}$** (立即刷新图像) , IDR 图像都是 I 帧图像。I和IDR帧都使⽤帧内预测。I帧不用参考任何帧 , 但是之后的P帧和B帧是有可能参考这个I帧之前的帧的。IDR就不允许这样。比如 (解码的顺序) : 

* **$\color{SkyBlue}{\mathbf{IDR1}}$** P4 B2 B3 **$\color{red}{\mathbf{P7}}$** B5 B6 **$\color{red}{\mathbf{I10}}$** **$\color{red}{\mathbf{B8}}$** B9 P13 B11 B12 P16 B14 B15 这⾥的 B8 可以跨过 I10 去参考 P7 
  * **$\color{SkyBlue}{原始图像}$** : **$\color{SkyBlue}{\mathbf{IDR1}}$** B2 B3 P4 B5 B6 **$\color{red}{\mathbf{P7}}$** **$\color{red}{\mathbf{B8}}$** B9 **$\color{red}{\mathbf{I10}}$**

* **$\color{SkyBlue}{\mathbf{IDR1}}$** P4 B2 B3 P7 B5 B6 **$\color{SkyBlue}{\mathbf{IDR8}}$** P11 B9 B10 P14 B11 B12 这里的B9就只能参照 IDR8 和 P11 , 不可以参考 **$\color{red}{\mathbf{IDR8}}$​** 前⾯的帧
* 说明 : 为什么不是顺序呢?原因是B2 B3帧解码需要参考前后 I 或 P帧 , 所以需先解码 I 或 P帧 , B帧不作为其他帧的参考帧

其核心作⽤是 , 是为了解码的重同步 , 当解码器解码到 IDR 图像时 , **$\color{red}{立即将参考帧队列清空}$** , 将已解码的数据全部输出或抛弃 , 重新查找参数集 , 开始⼀个新的序列。这样 , 如果前⼀个序列出现重大错误 , 在这⾥可以获得重新同步的机会。IDR图像之后的图像永远不会使用IDR之前的图像的数据来解码

下⾯是⼀个H264码流的举例 (从码流的帧分析可以看出来B帧不能被当做参考帧)

  <img src="assets/image-20240202163632591.png" alt="image-20240202163632591" /> 

> ```tex
> 一个直播推流的例子
> I0 B40 B80 B120 P160
> I0 B160
> I帧先编码,第一个B帧到来需40ms,第二个B帧到来需80ms,第三个B帧到来需120ms,到P帧来的时候已经是160ms了(以25fps为例,帧间隔时间是40ms),发送的时候需要等到P帧的到来才能发送,这个时候先发送I帧,等到发送一个B帧已经是160ms了,这样直播效果就很差,B帧数量太多了,一般直播的时候,不会插入B帧
> ```

# 7. NALU

<img src="assets/image-20240202163717955.png" alt="image-20240202163717955" /> 

SPS : 序列参数集 , SPS中保存了⼀组编码视频序列 (Coded video sequence) 的全局参数
PPS : 图像参数集 , 对应的是⼀个序列中某⼀幅图像或者某几幅图像的参数
I帧 : 帧内编码帧 , 可独立解码⽣成完整的图片
P帧 : 前向预测编码帧 , 需要参考其前⾯的⼀个I 或者 B 来⽣成⼀张完整的图片
B帧 : 双向预测内插编码帧 , 则要参考其前⼀个 I或者P帧 及其后⾯的⼀个P帧来⽣成⼀张完整的图片

> ```tex
> 发I帧之前,至少要发⼀次SPS和PPS,不需要每个I帧都发送一次SPS和PPS,如果码流中途有 编码参数改变 或 分辨率改变等,需重新发送一次SPS和PPS
> ```

## 7.1 NALU结构

H.264原始码流(裸流)是由⼀个接⼀个NALU组成 , 它的功能分为两层 , VCL(视频编码层) 和 NAL(⽹络提取层) : 

* VCL : 包括核心压缩引擎和块 , 宏块和片的语法级别定义 , 设计⽬标是尽可能地独立于网络进行高效的编码
* NAL : 负责将VCL产生的比特字符串适配到各种各样的网络和多元环境中 , 覆盖了所有片级以上的语法级别

在VCL进行数据传输或存储之前 , 这些编码的VCL数据 , 被映射或封装进NAL单元(NALU)

> ```tex
> ⼀个NALU = ⼀组对应于视频编码的NALU头部信息 + ⼀个原始字节序列负荷(RBSP,RawByte Sequence Payload).
> ```

NALU结构单元的主体结构如下所示 ; ⼀个原始的H.264 NALU单元 **$\color{SkyBlue}{通常由}$** 

**$\color{red}{\mathbf{[Start\ Code]\ [NALU\ Header]\ [NALU\ Payload]}}$**

三部分组成 , 其中 Start Code ⽤于标示这是⼀个NALU 单元的开始 , 必须是 "00 00 00 01" 或 "00 00 01" , 除此之外基本相当于⼀个NAL header + RBSP

<img src="assets/image-20240202164114061.png" alt="image-20240202164114061" /> 

> ```tex
> 对于FFmpeg解复⽤后,MP4⽂件读取出来的packet是不带startcode,但TS⽂件读取出来的packet带了startcode  
> ```

## 7.2 解析NALU

每个NAL单元是⼀个⼀定语法元素的可变⻓字节字符串 , 包括包含 **$\color{red}{\mathbf{⼀个字节的头信息}}$** (⽤来表示数据类型) , 以及若干整数字节的 **$\color{red}{负荷数据(\mathbf{Payload)}}$**

NALU头信息(⼀个字节) :

 <img src="assets/image-20240202164222829.png" alt="image-20240202164222829" style="zoom:150%;" /> 

其中 :

- **T为负荷** **$\color{red}{数据类型}$** , 占 **$\color{red}{\mathbf{5bit}}$**
  - nal_unit_type : 这个NALU单元的类型 , 1～12 由H.264使用 , 24～31由H.264以外的应用使用
- **R为重要性指示位** , **占2个bit** 
  - nal_ref_idc. : 取00~11 , 似乎指示这个NALU的重要性 , 如00的NALU解码器可以丢弃它而不影响图像的回放 , 0～3 , 取值越大 , 表示当前NAL越重要 , 需要优先受到保护。如果当前NAL是属于参考帧的片, 或是序列参数集 , 或是图像参数集这些重要的单位时 , 本句法元素必需大于0

- **最后的F为禁⽌位 , 占1bit**
  - forbidden_zero_bit : 在 H.264 规范中规定了这⼀位必须为0.

**H.264标准指出 , 当数据流是储存在介质上时 , 在每个NALU 前添加起始码 : 0x000001 或 0x00000001 , ⽤来指示⼀个NALU 的起始和终止位置** : 

* 在这样的机制下 , 在码流中检测起始码 , 作为⼀个NALU得起始标识 , 当检测到下⼀个起始码时 , 当前NALU结束。
* 3字节的0x000001只有⼀种场合下使用 , 就是⼀个完整的帧被编为多个slice(片)的时候 , 包含这些slice的NALU使用3字节起始码。其余场合都是4字节0x00000001的

例子 : 

> ```c++
> 0x00 00 00 01(前4个字节为start code) 67(NAL header) …
> 0x00 00 00 01 68 …
> 解析NALU8
> 0x00 00 00 01 65 …
> 67(NAL header):
> ⼆进制:0110 0111
> 00111 = 7(⼗进制)
> ```

| nal_unit_type | NAL 单元和 RBSP 语法结构的内容                               |
| ------------- | ------------------------------------------------------------ |
| 0             | 未指定                                                       |
| 1             | ⼀个⾮IDR图像的编码条带 <br />slice_layer_without_partitioning_rbsp () |
| 2             | 编码条带数据分割块A <br />slice_data_partition_a_layer_rbsp() |
| 3             | 编码条带数据分割块B <br />slice_data_partition_b_layer_rbsp() |
| 4             | 编码条带数据分割块C <br />slice_data_partition_c_layer_rbsp() |
| 5             | IDR图像的编码条带(片) <br />slice_layer_without_partitioning_rbsp () |
| 6             | 辅助增强信息(SEI) <br />sei_rbsp()                           |
| 7             | 序列参数集 <br />seq_parameter_set_rbsp()                    |
| 8             | 图像参数集 <br />pic_parameter_set_rbsp()                    |
| 9             | 访问单元分隔符 <br />access_unit_delimiter_rbsp()            |
| 10            | 序列结尾 <br />end_of_seq_rbsp()                             |
| 11            | 流结尾 <br />end_of_stream_rbsp()                            |
| 12            | 填充数据 <br />filler_data_rbsp()                            |
| 13            | 序列参数集扩展<br />seq_parameter_set_extension_rbsp()       |
| 14...18       | 保留                                                         |
| 19            | 未分割的辅助编码图像的编码条带 <br />slice_layer_without_partitioning_rbsp( ) |
| 20..23        | 保留                                                         |
| 24...31       | 未指定                                                       |

> ```tex
> 对于NALU分析这节课主要关注5/6/7/8 四种类型
> ```

# 8. H264 annexb模式

H264有两种封装

* ⼀种是annexb模式 , 传统模式 , 有startcode , SPS和PPS是在ES中
* ⼀种是mp4模式 , ⼀般mp4 mkv都是mp4模式，没有startcode，SPS和PPS以及其它信息被封装在container中 , 每⼀个frame前⾯4个字节是这个frame的长度

很多解码器只⽀持annexb这种模式 , 因此需要将mp4做转换 : 在ffmpeg中用 h264_mp4toannexb_filter 可以做转换 

实现 : 

> ```c++
> const AVBitStreamFilter *bsfilter = av_bsf_get_by_name("h264_mp4toannexb");
> 
> AVBSFContext *bsf_ctx = NULL;
> 
> // 2 初始化过滤器上下⽂
> av_bsf_alloc(bsfilter, &bsf_ctx); //AVBSFContext;
> // 3 添加解码器属性
> avcodec_parameters_copy(bsf_ctx->par_in, ifmt_ctx->streams[videoindex]->codecpar);
> 
> av_bsf_init(bsf_ctx);
> 
> ```

# 9. 补充讲解

## GOP group of pictures

GOP 指的就是两个I帧之间的间隔. 比如说GOP为120,如果是720 p60 的话 , 那就是2s⼀次I帧
在视频编码序列中 , 主要有三种编码帧：I帧、P帧、B帧，如下所示：

* I帧即 Intra-coded picture (帧内编码图像帧) , 不参考其他图像帧 , 只利⽤本帧的信息进行编码
* P帧即 Predictive-codedPicture (预测编码图像帧) ,利⽤之前的I帧或P帧 , 采⽤运动预测的⽅式进⾏帧间预测编码
* B帧即 Bidirectionallypredicted picture (双向预测编码图像帧) 提供最高的压缩比 , 它既需要之前的图像帧 (I帧或P帧) , 也需要后来的图像帧 (P帧) , 采⽤运动预测的⽅式进行帧间双向预测编码

在视频编码序列中 , GOP即Group of picture (图像组) , 指两个I帧之间的距离 , Reference (参考周期) 指两个P帧之间的距离。⼀个I帧所占⽤的字节数⼤于⼀个P帧 , ⼀个P帧所占⽤的字节数大于⼀个B帧  

所以在码率不变的前提下 , GOP值越大 , P、B帧的数量会越多 , 平均每个I、P、B帧所占⽤的字节数就越多 , 也就更容易获取较好的图像质量;Reference越大 , B帧的数量越多 , 同理也更容易获得较好的图像质量

需要说明的是 , 通过提⾼GOP值来提⾼图像质量是有限度的 , 在遇到场景切换的情况时 , H.264编码器会⾃动强制插入⼀个I帧 , 此时实际的GOP值被缩短了。另一方面，在⼀个GOP中，P、B帧是由I帧预测得到的 , 当I帧的图像质量比较差时，会影响到⼀个GOP中后续P、B帧的图像质量 , 直到下⼀个GOP开始才有可能得以恢复 , 所以GOP值也不宜设置过大。同时 , 由于P、B帧的复杂度大于 I帧，所以过多的P、B帧会影响编码效率 , 使编码效率降低。另外 , 过长的GOP还会影响Seek操作的响应速度 , 由于P、B帧是由前⾯的I或P帧预测得到的，所以Seek操作需要直接定位 , 解码某⼀个P或B帧时 , 需要先解码得到本GOP内的I帧及之前的N个预测帧才可以 , GOP值越⻓ , 需要解码的预测帧就越多 , seek响应的时间也越⻓。  

# 10. H.264中的 I帧 , B帧 , P帧

在H264中的图像以序列为单位进行组织 , ⼀个序列是⼀段图像编码后的数据流 , 以I帧开始 , 到下⼀个I帧结束。
IDR图像 : ⼀个序列的第⼀个图像叫做IDR图像 (立即刷新图像) , IDR 图像都是I帧图像。H.264引入IDR图像是为了解码的重同步，当解码器解码到IDR图像时 , 立即将参考帧队列清空 , 将已解码的数据全部输出或抛弃 , 重新查找参数集 , 开始⼀个新的序列。这样 , 如果前⼀H.264中的I帧 , B帧和P帧11个序列出现重大错误 , 在这⾥获得重新同步的机会。IDR图像之后的图像永远不会使用IDR之前的图像数据来解码。
⼀个序列就是⼀段内容差别不是很大的图像编码后生成的⼀串数据流。当运动变化比较少的时候 , ⼀个序列可以很长 , 因为运动变化的少就代表图像画面的内容变动很小，所以就可以编⼀个I帧，然后⼀直P帧、B帧了。当运动变化多时 , 可能⼀个序列就比较短了 , 比如就包含⼀个I帧和3、4个P帧。  

## 10.1 I P B三种帧的说明

### 10.1.1 I帧

帧内编码帧 , I帧表示关键帧 , 你可以理解为这⼀帧画⾯的完整保留 ; 解码时只需要本帧数据就可以完成 (因为包含完整画⾯)

特点 : 

1) 它是⼀个全帧压缩编码帧。它将全帧图像信息进行JPEG压缩编码及传输
2) 解码时仅用I帧的数据就可重构完整图像
3) I帧描述了图像背景和运动主体的详情
4) I帧不需要参考其他画面而生成
5) I帧是P帧和B帧的参考帧(其质量直接影响到同组中以后各帧的质量)
6) I帧是帧组GOP的基础帧(如果为IDR则为第⼀帧) , 在⼀组中只有⼀个IDR帧 , ⼀个或多个I帧 (包括IDR帧)
7) I帧不需要考虑运动矢量
8) I帧所占数据的信息量比较大

### 10.1.2 P帧

* P帧 : 前向预测编码帧。P帧表示的是这⼀帧跟之前的⼀个关键帧 (或P帧) 的差别 , 解码时需要用之前缓存的画面叠加上本帧定义的差别 , 生成最终画面 (也就是差别帧 , P帧没有完整画面数据 , 只有与前⼀帧的画面差别的数据) 
* P帧的预测与重构 : P帧是以I帧为参考帧 , 在I帧中找出P帧 "某点" 的 **$\color{red}{预测值和运动矢量}$​** , 取预测差值和运动矢量⼀起传送。在接收端根据运动矢量从I帧中找出P帧 "某点" 的预测值并与差值相加以得到P帧 "某点" 样值 , 从而可得到完整的P帧。
* P帧特点 : 
  1) P帧是I帧后面相隔1~2 帧的编码帧;
  1) P帧采用运动补偿的方法传送它与前面的I或P帧的差值及运动矢量 (预测误差);
  1) 解码时必须将I帧中的预测值与预测误差求和后才能重构完整的P帧图像;
  1) P帧属于前向预测的帧间编码。它只参考前前面最靠近它的I帧或P帧;
  1) P帧可以是其后面P帧的参考帧 , 也可以是其前后的B帧的参考帧;
  1) **$\color{red}{\mathbf{由于P帧是参考帧}}$** , 它可能造成解码错误的扩散;
  1) 由于是差值传送 , P帧的压缩比较⾼。


### 10.1.3 B帧

* B帧 : 双向预测内插编码帧。B帧是双向差别帧 , 也就是B帧记录的是本帧与前后帧的差别 (具体比较复杂 , 有4种情况 , 但我这样说简单些) , 换⾔之 , 要解码B帧 , 不仅要取得之前的缓存画面 , 还要解码之后的画面 , 通过前后画面的与本帧数据的叠加取得最终的画面。B帧压缩率高 , 但是解码时CPU会⽐较累

* B帧的预测与重构 : B帧以前面的 I 或 P帧 和 后面的P帧为参考帧 , "找出" B帧 "某点" 的预测值 和两个运动矢量 , 并取预测差值和运动矢量传送。接收端根据运动矢量在两个参考帧中 "找出(算出)" 预测值并与差值求和 , 得到B帧 "某点" 样值 , 从而可得到完整的B帧。

* B帧特点

  * B帧是由前⾯的I或P帧和后⾯的P帧来进行预测的;

  * B帧传送的是它与前⾯的I或P帧和后⾯的P帧之间的预测误差及运动⽮量;

  * B帧是双向预测编码帧;

  * B帧压缩比最高 , 因为它只反映两参考帧间运动主体的变化情况 , 预测比较准准确;

  * B帧不是参考帧 , 不会造成解码错误的扩散


> ```tex
> 注:I、B、P各帧是根据压缩算法的需要,是⼈为定义的,它们都是实实在在的物理帧。⼀般来说,I帧的压缩率是7(跟JPG差不多),P帧是20,B帧可以达到50。可⻅使⽤B帧能节省⼤量空间,节省出来的空间可以⽤来保存多⼀些I帧,这样在相同码率下,可以提供更好的画质
> ```

# 11. 编程实验

[[工程参考链接]](/code/win/2-FFmpeg/04-extract-h264)

> ```c++
> #include <iostream>
> #include <fstream>
> 
> extern "C" {
> #include <libavutil/log.h>
> #include <libavformat/avio.h>
> #include <libavformat/avformat.h>
> #include <libavcodec/bsf.h>
> }
> 
> using namespace std;
> 
> static char* av_get_err(const int errnum)
> {
>     static char err_buf[128] {};
>     av_strerror(errnum, err_buf, sizeof(err_buf));
>     return err_buf;
> }
> 
> /*
> AvCodecContext->extradata[]中为nalu长度
> *   codec_extradata:
> *   1, 64, 0, 1f, ff, e1, [0, 18], 67, 64, 0, 1f, ac, c8, 60, 78, 1b, 7e,
> *   78, 40, 0, 0, fa, 40, 0, 3a, 98, 3, c6, c, 66, 80,
> *   1, [0, 5],68, e9, 78, bc, b0, 0,
> */
> 
> //ffmpeg -i 2018.mp4 -codec copy -bsf:h264_mp4toannexb -f h264 tmp.h264
> //ffmpeg 从mp4上提取H264的nalu h
> 
> int main(int argc, char **argv)
> {
>     if(argc < 3){
>         cerr << "usage inputfile outfile\n";
>         return -1;
>     }
> 
>     //FILE *outfp=fopen(argv[2],"wb");
>     ofstream outfp(argv[2],ios::binary | ios::trunc);
>     cout << "in: " << argv[1] << " , out: " << argv[2] << "\n";
> 
>     // 分配解复用器的内存，使用avformat_close_input释放
>     auto ifmt_ctx {avformat_alloc_context()};
>     if (!ifmt_ctx){
>         outfp.close();
>         cerr << "[error] Could not allocate context.\n";
>         return -1;
>     }
> 
>     // 根据url打开码流，并选择匹配的解复用器
>     auto ret { avformat_open_input(&ifmt_ctx,argv[1], nullptr, nullptr)};
>     if(ret < 0){
>         outfp.close();
>         cerr << "[error]avformat_open_input: " << av_get_err(ret) << "\n";
>         return -1;
>     }
> 
>     // 读取媒体文件的部分数据包以获取码流信息
>     ret = avformat_find_stream_info(ifmt_ctx, nullptr);
>     if(ret < 0){
>         outfp.close();
>         avformat_close_input(&ifmt_ctx);
>         cerr << "[error]avformat_find_stream_info: " << av_get_err(ret) << "\n";
>         return -1;
>     }
> 
>     // 查找出哪个码流是video/audio/subtitles
> 
>     const auto videoindex {av_find_best_stream(ifmt_ctx, AVMEDIA_TYPE_VIDEO, -1, -1, nullptr, 0)};
>     if(videoindex < 0){
>         cerr << "Didn't find a video stream.\n";
>         outfp.close();
>         avformat_close_input(&ifmt_ctx);
>         return -1;
>     }
> 
>     // 1 获取相应的比特流过滤器
>     // FLV/MP4/MKV等结构中,h264需要h264_mp4toannexb处理。添加SPS/PPS等信息。
>     // FLV封装时，可以把多个NALU放在一个VIDEO TAG中,结构为4B NALU长度+NALU1+4B NALU长度+NALU2+...,
>     // 需要做的处理把4B长度换成0x00000001或者0x000001
>     const auto bsfilter {av_bsf_get_by_name("h264_mp4toannexb")};
>     AVBSFContext *bsf_ctx {};
>     // 2 初始化过滤器上下文
>     av_bsf_alloc(bsfilter, &bsf_ctx); //AVBSFContext;
>     // 3 添加解码器属性
>     avcodec_parameters_copy(bsf_ctx->par_in, ifmt_ctx->streams[videoindex]->codecpar);
> 
>     av_bsf_init(bsf_ctx);
> 
>     auto pkt {av_packet_alloc()};   // 分配数据包
> 
>     bool file_end {}; // 文件是否读取结束
> 
>     while (!file_end){
> 
>         if((ret = av_read_frame(ifmt_ctx, pkt)) < 0){
>             // 没有更多包可读
>             file_end = true;
>             cout << "read file end: ret: " << ret << "\n";
>         }
> 
>         if((!ret) && (videoindex == pkt->stream_index)){
> #if 1
>             const auto input_size {pkt->size};
> 
>             if (av_bsf_send_packet(bsf_ctx, pkt)) {    // bitstreamfilter内部去维护内存空间
>                 av_packet_unref(pkt);   // 你不用了就把资源释放掉
>                 continue;       // 继续送
>             }
> 
>             av_packet_unref(pkt);   // 释放资源
> 
>             int out_pkt_count {};/*用于统计一个packet是否含有多个NALU,有些视频把SEI SPS PPS I帧放在同一个packet*/
> 
>             while(!av_bsf_receive_packet(bsf_ctx, pkt)){/*自动加入start code*/
> 
>                 ++out_pkt_count;
> 
>                 cout << "write pkt size: " << pkt->size << "\n" << flush;
> 
>                 const auto begin_size{outfp.tellp()};
> 
>                 outfp.write(reinterpret_cast<char*>(pkt->data),pkt->size);
> 
>                 const auto size {outfp.tellp() - begin_size};
> 
>                 if(size != pkt->size){
>                     cerr << "write failed-> write: " << size << ", pkt_size : " << pkt->size << "\n";
>                 }
> 
>                 av_packet_unref(pkt);
>             }
> 
>             if(out_pkt_count >= 2){
>                 cout << "cur pkt(size: " << input_size << ") only get 1 out pkt, it get " << 								out_pkt_count << " pkts\n";
>             }
> #else       // TS流可以直接写入
>             const auto begin_size{outfp.tellp()};
> 
>             outfp.write(reinterpret_cast<char*>(pkt->data),pkt->size);
> 
>             const auto size {outfp.tellp()-begin_size};
> 
>             if(size != pkt->size){
>                 cerr << "write failed-> write: " << size << ", pkt_size : " << pkt->size << "\n";
>             }
> 
>             av_packet_unref(pkt);
> #endif
>         }else{
>             if(!ret){
>                 av_packet_unref(pkt);        // 释放内存
>             }
>         }
>     }
> 
>     outfp.close();
> 
>     if(bsf_ctx){
>         av_bsf_free(&bsf_ctx);
>     }
> 
>     if(pkt){
>         av_packet_free(&pkt);
>     }
> 
>     if(ifmt_ctx){
>         avformat_close_input(&ifmt_ctx);
>     }
> 
>     cout << "finish\n";
>     return 0;
> }
> ```

## 11.1 实验一

> ```tex
> mp4文件读取后通过av_bsf_send_packet(...) av_bsf_receive_packet(...)处理输出h264文件可以正常播放,没有经过av_bsf_send_packet(...) av_bsf_receive_packet(...)处理的,不能正常播放,原因在于没有startcode
> ```

<img src="assets/image-20240219151618044.png" alt="image-20240219151618044" style="zoom:200%;" /><img src="assets/image-20240219151926260.png" alt="image-20240219151926260" /> 

<img src="assets/image-20240219152008422.png" alt="image-20240219152008422" /> 

> ```tex
> flv文件与MP4文件类似,输出h264文件没有startcode同样无法播放,这里不做重复的实验了,直接给出实验的结论
> ```

## 11.2 实验二

> ```tex
> ts流可以直接读取并输出h264文件,不进行av_bsf_send_packet(...)与av_bsf_receive_packet(...)处理,也是可以的,
> 实验就不重复了,这里直接给出实验的结论
> ```

